{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02df3662-28a2-4c11-94c1-19dacb1d00d1",
   "metadata": {},
   "source": [
    "# Topic Modeling: probabilistic LSA / Non-negative Matrix Factorization\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be72f9d-d9b9-4a51-87bb-8306992ef6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualziation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Path & Random\n",
    "from pathlib import Path\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4d2a19-aa3b-485a-95ae-27a7c1e18292",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22653382-727e-4b1a-9f37-eb1c14b000c5",
   "metadata": {},
   "source": [
    "### Loading BBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfb9f25-eb09-4e5f-8472-3c3ee2f3a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47e39a1-fa62-4284-8181-a89ef2429cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA_DIR / 'bbc'\n",
    "\n",
    "files = sorted(list(path.glob('**/*.txt')))\n",
    "\n",
    "doc_list = []\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    with open(str(file), encoding='latin1') as f:\n",
    "        topic = file.parts[-2]\n",
    "        lines = f.readlines()\n",
    "        heading = lines[0].strip()\n",
    "        body = ' '.join([l.strip() for l in lines[1:]])\n",
    "        doc_list.append([topic.capitalize(), heading, body])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d237d-5205-4362-a278-0d89e2c9dcd6",
   "metadata": {},
   "source": [
    "#### DataFrame Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f119ff4-77c9-4657-8f43-78f7dc0703a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(doc_list, columns=['Category', 'Heading', 'Article'])\n",
    "\n",
    "docs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c958bc-98ff-4f35-98ce-7e0b772ce842",
   "metadata": {},
   "source": [
    "### Creating Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53df3ace-7b07-450c-8d72-77a9c7209915",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs, test_docs = train_test_split(docs, \n",
    "                                         stratify=docs.Category, \n",
    "                                         test_size=50, \n",
    "                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bef1d16-6625-4128-bfbe-4826c4aa7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs.shape, test_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b210ea-55cc-4d09-933a-0138d2d6d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_docs.Category).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2312d-3bd0-439f-a3e6-9daa518d68c1",
   "metadata": {},
   "source": [
    "### Vectorizing Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd96a4b-00dc-4296-8375-fe2f4a308afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=.2, \n",
    "                             min_df=.01, \n",
    "                             stop_words='english')\n",
    "\n",
    "train_dtm = vectorizer.fit_transform(train_docs.Article)\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a30d972-cc90-4221-a2b9-d5023bf751bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm = vectorizer.transform(test_docs.Article)\n",
    "\n",
    "test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbadce2-4ecf-46af-b344-8165a3481249",
   "metadata": {},
   "source": [
    "### Getting Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d515656a-c8a7-4f37-aa9d-1d141dcc6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token_count = train_dtm.sum(0).A.squeeze()\n",
    "\n",
    "tokens = vectorizer.get_feature_names()\n",
    "\n",
    "word_count = pd.Series(train_token_count, index=tokens).sort_values(ascending=False)\n",
    "word_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b317aa-e5e1-4e19-b3b2-a1f0c948714e",
   "metadata": {},
   "source": [
    "### Probabilistic Latent Semantic Analysis\n",
    "\n",
    "#### Implementation using Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd7460a-c868-42f6-b556-ea2c460376c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "\n",
    "topic_labels = ['Topic {}'.format(i) for i in range(1, n_components+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cfffb1c-ca16-4cab-b0a0-77b0dcb5628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=n_components, \n",
    "          random_state=42, \n",
    "          solver='mu',\n",
    "          beta_loss='kullback-leibler', \n",
    "          max_iter=1000)\n",
    "\n",
    "nmf.fit(train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69bbf147-8aaf-46c8-8c6d-841b36444f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d9abe-1467-499f-8343-fd51958338e8",
   "metadata": {},
   "source": [
    "### Exploring Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9038902-8cab-444c-bd2d-ea10164788ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_topics = nmf.transform(train_dtm)\n",
    "\n",
    "train_doc_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0319604c-cdf7-489f-99f1-6e3b06e6e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = randint(0, len(train_docs))\n",
    "\n",
    "(train_docs.iloc[i, :2].append(pd.Series(train_doc_topics[i], \n",
    "                                         index=topic_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70ee95d2-5f97-4f8f-94eb-acdb43253d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = pd.DataFrame(data=train_doc_topics,\n",
    "                   columns=topic_labels,\n",
    "                   index=train_docs.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146dc724-5a6a-4892-9de8-f7604aa413f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = pd.DataFrame(data=nmf.transform(test_dtm), \n",
    "                         columns=topic_labels,\n",
    "                         index=test_docs.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8713f079-c4bb-4700-bcb6-30c50f684310",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.melt(train_result.assign(Data='Train')\n",
    "                 .append(test_eval.assign(Data='Test'))\n",
    "                 .reset_index(),\n",
    "                 id_vars=['Data', 'Category'],\n",
    "                 var_name='Topic',\n",
    "                 value_name='Weight')\n",
    "\n",
    "result = pd.melt(train_result.assign(Data='Train')\n",
    "                 .append(test_eval.assign(Data='Test'))\n",
    "                 .reset_index(),\n",
    "                 id_vars=['Data', 'Category'],\n",
    "                 var_name='Topic',\n",
    "                 value_name='Weight')\n",
    "\n",
    "g =sns.catplot(x='Category', \n",
    "               y='Weight', \n",
    "               hue='Topic', \n",
    "               row='Data', \n",
    "               kind='bar', \n",
    "               data=result, \n",
    "               height=3,\n",
    "               aspect=4);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316df1c-052d-4bd9-b172-5a83e7ebe4f6",
   "metadata": {},
   "source": [
    "#### Most Important Words by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc5a5024-645c-4bd7-9c31-876b9031ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame(nmf.components_.T,\n",
    "                      index=tokens,\n",
    "                      columns=topic_labels)\n",
    "\n",
    "topics.loc[word_count.head(10).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ea2562c-0650-40a7-86e0-3d40742b6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "top_words, top_vals = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "for topic, words_ in topics.items():\n",
    "    top10 = words_.nlargest(10).index\n",
    "    vals = words_.loc[top10].values\n",
    "    top_vals[topic] = vals\n",
    "    top_words[topic] = top10.tolist()\n",
    "\n",
    "sns.heatmap(pd.DataFrame(top_vals), \n",
    "            annot=top_words, \n",
    "            fmt = '', \n",
    "            center=0, \n",
    "            cmap=sns.diverging_palette(0, 255, sep=1, n=256), \n",
    "            ax=ax);\n",
    "\n",
    "ax.set_title('Top Words per Topic')\n",
    "fig.tight_layout();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a58b9820-6792-436d-90eb-467acd62e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame(nmf.components_.T,\n",
    "                      index=words,\n",
    "                      columns=topic_labels)\n",
    "\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12d4db0d-9e5f-4c2a-bbaf-9e747102516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = {}\n",
    "\n",
    "for topic, words_ in topics.items():\n",
    "    top_words[topic] = words_.nlargest(10).index.tolist()\n",
    "\n",
    "pd.DataFrame(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e407cc-3076-472f-83fb-355558f39588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5cfd1-5618-41ba-b9c7-84d0e816cb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
