{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5205090e-c2d1-479a-8e42-f7503d351e9e",
   "metadata": {},
   "source": [
    "# Long-Short Strategy, Part 2: Trading Signals with LightGBM & CatBoost\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75e3c0e-af43-49d1-a5ec-c8414557030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# pATH\n",
    "from pathlib import Path\n",
    "\n",
    "# OS & Time\n",
    "import sys, os\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# SciPy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Data Visualization\n",
    "import graphviz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Itertool & Collections\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "# Technical Analysis\n",
    "import talib\n",
    "from talib import RSI, BBANDS, MACD, ATR\n",
    "\n",
    "# Boosting Models\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# Alphalens\n",
    "from alphalens.tears import (create_summary_tear_sheet,\n",
    "                             create_full_tear_sheet)\n",
    "\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd50169a-9d3a-4a74-bf22-dc4b1ee2f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abe9a3ee-fe10-4f9c-8662-a1aeb407e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f82afc3-c96b-433a-93fe-b940b5bf173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ab5a68-e76e-4cb9-b4d9-95f3e62c4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3777ab47-4b59-48da-ad7e-6387c86418ac",
   "metadata": {},
   "source": [
    "### Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11fb417-8a3f-420f-9ac8-2b5f7149d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_hdf('data.h5', 'model_data')\n",
    "            .sort_index()\n",
    "            .loc[idx[:, :'2016'], :]) \n",
    "\n",
    "data.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb77713d-e7f5-48b5-823b-94446e902d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "\n",
    "features = data.columns.difference(labels).tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe61b2-fce5-44a6-8cf0-e7eefecf950f",
   "metadata": {},
   "source": [
    "### Model Selection: `Lookback, Lookahead & Roll-Forward Periods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3decc05a-877a-4c61-bcbd-9870ec4b7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = data.index.get_level_values('symbol').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "055e62a6-6758-4027-8739-48c8917d349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7d18544-54f2-49cf-9180-e3f8f87b834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "817ef3b6-0d02-4272-b0be-2f4f0773e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "\n",
    "test_lengths = [63, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05eb238c-cbd6-45c9-9028-791a5be21760",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "580cef0e-2946-4b15-b767-da490e1ad0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'us_stocks')\n",
    "\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33065dc-0832-49b7-b6d9-8868bead6892",
   "metadata": {},
   "source": [
    "### Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd0e4b44-5f3b-4e35-b958-3b03a8180c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "732bbb45-aa38-48a1-89f2-68f284ee8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics = []\n",
    "\n",
    "# iterate over our three CV configuration parameters\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'r{lookahead:02}_fwd'\n",
    "    df = pd.get_dummies(data.loc[:, features + [label]].dropna(), \n",
    "                        columns=categoricals, \n",
    "                        drop_first=True)\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([lookahead, \n",
    "                       train_length, \n",
    "                       test_length,\n",
    "                       np.mean(ic),\n",
    "                       spearmanr(preds.y_true, preds.y_pred)[0]\n",
    "                      ])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08156e9d-3897-4c26-be81-dc315f5a397a",
   "metadata": {},
   "source": [
    "### Information Coefficient - Distribution by Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e3e6537-4bbf-40e6-b03e-d3e08f08e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "\n",
    "# plot average of daily IC values\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "\n",
    "# plot IC across all predictions\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a7075-813b-4233-9221-a6246175284c",
   "metadata": {},
   "source": [
    "#### Best Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44776a7d-16ac-4a9c-bb93-57402b1e4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lr_metrics.groupby('lookahead', group_keys=False)\n",
    " .apply(lambda x: x.nlargest(3, 'ic_by_day')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9783a70d-6590-4a17-8524-e0ea5162fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics.to_csv(results_path / 'lin_reg_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e33334-da88-4b23-9248-d4afab35e356",
   "metadata": {},
   "source": [
    "### LightGBM Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdf1222f-49d6-4789-9518-b106814903d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "    \"\"\"Return normalized feature importance as pd.Series\"\"\"\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(),\n",
    "                      index=model.feature_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9f043-c884-48c9-a3a7-c67988748a49",
   "metadata": {},
   "source": [
    "#### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a292433-73f8-4472-9e0b-76152f06459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cace333f-451e-428c-b611-56f0d3b2fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [2, 3, 5, 7]\n",
    "num_leaves_opts = [2 ** i for i in max_depths]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]\n",
    "\n",
    "# weight of each new tree in the ensemble\n",
    "learning_rate_ops = [.01, .1, .3]\n",
    "\n",
    "# random feature selection\n",
    "feature_fraction_opts = [.3, .6, .95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2627832-534c-4be0-a481-316e483cb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'num_leaves',\n",
    "               'feature_fraction', 'min_data_in_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "139248d6-7ee6-4bd9-8af1-e570d288bdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 108\n"
     ]
    }
   ],
   "source": [
    "cv_params = list(product(learning_rate_ops,\n",
    "                         num_leaves_opts,\n",
    "                         feature_fraction_opts,\n",
    "                         min_data_in_leaf_opts))\n",
    "n_params = len(cv_params)\n",
    "\n",
    "print(f'# Parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396e7d4-e200-4c93-9c3b-73200ba5d488",
   "metadata": {},
   "source": [
    "#### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38304d34-25a4-4de4-8df6-66302c3329e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95f4efce-5e75-446b-81db-5dde34d17142",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fca1ac56-0385-4883-afb1-04875f0e469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "n = len(test_params)\n",
    "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
    "test_params = [test_params[i] for i in test_param_sample]\n",
    "\n",
    "print('Train configs:', len(test_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d10f8-fec2-49fe-aa5e-9868a1659eea",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe5d66a-2641-4d86-85e3-5a6a5c2a291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['year', 'weekday', 'month']\n",
    "\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b07d6-1835-4189-8904-d9a2bda4004a",
   "metadata": {},
   "source": [
    "### Custom Loss Function: Information Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c44b9f70-c9b8-42db-b72c-f1008c4bb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ic_lgbm(preds, train_data):\n",
    "    \"\"\"Custom IC eval metric for lightgbm\"\"\"\n",
    "    is_higher_better = True\n",
    "    return 'ic', spearmanr(preds, train_data.get_label())[0], is_higher_better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104dc9b-53d1-4674-8066-357e5b58727f",
   "metadata": {},
   "source": [
    "### Running Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fee66df-4e0f-4a79-8ea7-ceea24b869a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_store = Path(results_path / 'tuning_lgb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90518b51-01c5-4a8c-bdaf-32dcfcd52ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='fwd').columns)\n",
    "\n",
    "features = data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93c84abb-5f07-48f9-aa28-4d98d9884fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b9ae604-40b7-4968-a43a-0b74ae4a5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
    "\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e84e22c8-de2b-483a-b654-c7751a69add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b08eed5-78b9-4e2b-a8a9-fb6c4b676717",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    # randomized grid search\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 2),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    # set up cross-validation\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | '\n",
    "          f'Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | '\n",
    "          f'Params: {len(cv_params_):3.0f} | '\n",
    "          f'Train configs: {len(test_params)}')\n",
    "\n",
    "    # time-series cross-validation\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    \n",
    "    # binary dataset\n",
    "    lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1),\n",
    "                           label=outcome_data[label],\n",
    "                           categorical_feature=categoricals,\n",
    "                           free_raw_data=False)\n",
    "    T = 0\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    \n",
    "    # iterate over (shuffled) hyperparameter combinations\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        key = f'{lookahead}/{train_length}/{test_length}/' + '/'.join([str(p) for p in param_vals])\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params.update(base_params)\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        \n",
    "        # iterate over folds\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            \n",
    "            # select train subset\n",
    "            lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                       params=params).construct()\n",
    "            \n",
    "            # train model for num_boost_round\n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=lgb_train,\n",
    "                              num_boost_round=num_boost_round,\n",
    "                              verbose_eval=False)\n",
    "            # log feature importance\n",
    "            if i == 0:\n",
    "                fi = get_fi(model).to_frame()\n",
    "            else:\n",
    "                fi[i] = get_fi(model)\n",
    "\n",
    "            # capture predictions\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_name()]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
    "            \n",
    "            # record predictions for each fold\n",
    "            cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
    "        \n",
    "        # combine fold results\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        \n",
    "        # compute IC per day\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "        \n",
    "        # compute IC across all predictions\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        \n",
    "        # collect metrics\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'\\t{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"learning_rate\"]:5.2f} | '\n",
    "        msg += f'{params[\"num_leaves\"]:3.0f} | {params[\"feature_fraction\"]:3.0%} | {params[\"min_data_in_leaf\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "\n",
    "        # persist results for given CV run and hyperparameter combination\n",
    "        metrics.to_hdf(lgb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(lgb_store, 'daily_ic/' + key)\n",
    "        fi.T.describe().T.assign(**params).to_hdf(lgb_store, 'fi/' + key)\n",
    "        cv_preds.to_hdf(lgb_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a5868-a794-4bd4-a799-bf8368d184b9",
   "metadata": {},
   "source": [
    "### CatBoost Model Tuning\n",
    "\n",
    "#### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6ffe005-76e5-4a61-8369-896f69d25701",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['max_depth', 'min_child_samples']\n",
    "\n",
    "max_depth_opts = [3, 5, 7, 9]\n",
    "min_child_samples_opts = [20, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "046d7604-3b3d-4124-9f96-88c5464c215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = list(product(max_depth_opts,\n",
    "                         min_child_samples_opts))\n",
    "\n",
    "n_params = len(cv_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ac137-f168-4a45-bfd8-90a6a02d8473",
   "metadata": {},
   "source": [
    "### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40caa486-2b1a-46cd-9c65-90e50c15d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11db354e-1a59-460c-95a4-deff11de17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 252), 252]\n",
    "\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e97dca2f-dad1-4128-80e7-7fe8464b3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads,\n",
    "                           train_lengths,\n",
    "                           test_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb843c-72e4-4652-9846-b22ed2782e6a",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff00bd26-f7c7-41fd-99a5-14ad2413c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostIC(object):\n",
    "    \"\"\"Custom IC eval metric for CatBoost\"\"\"\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # Returns whether great values of metric are better\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        target = np.array(target)\n",
    "        approxes = np.array(approxes).reshape(-1)\n",
    "        rho = spearmanr(approxes, target)[0]\n",
    "        return rho, 1\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        # Returns final value of metric based on error and weight\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6a365-c281-4e2d-8c48-146047353d9a",
   "metadata": {},
   "source": [
    "### Running Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45de1c52-70fa-4379-b49c-411ff0f24186",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_store = Path(results_path / 'tuning_catboost.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88c46960-93ef-4c46-aec5-b7ecda4ccce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 1001, 100))\n",
    "\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "285f7638-a922-44c4-922e-b7d585f8d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44d4d7ae-ebbe-4825-a58c-3ab0c0ea0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 1),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | Params: {len(cv_params_):3.0f} | Train configs: {len(test_params)}')\n",
    "\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    cat_cols_idx = [outcome_data.columns.get_loc(c) for c in categoricals]\n",
    "    catboost_data = Pool(label=outcome_data[label],\n",
    "                         data=outcome_data.drop(label, axis=1),\n",
    "                         cat_features=cat_cols_idx)\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    key = f'{lookahead}/{train_length}/{test_length}'\n",
    "    T = 0\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        # uncomment if running with GPU\n",
    "#         params['task_type'] = 'GPU'\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "            model = CatBoostRegressor(**params)\n",
    "            model.fit(X=train_set,\n",
    "                      verbose_eval=False)\n",
    "\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_names_]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, ntree_end=n)\n",
    "                      for n in num_iterations}\n",
    "            cv_preds.append(y_test.to_frame(\n",
    "                'y_test').assign(**y_pred).assign(i=i))\n",
    "\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0]\n",
    "              for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n,\n",
    "                             daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"max_depth\"]:3.0f} | {params[\"min_child_samples\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "        metrics.to_hdf(cb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(cb_store, 'daily_ic/' + key)\n",
    "        cv_preds.to_hdf(cb_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a1ac9-1c24-44a0-a6d0-d53ad5a997af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
