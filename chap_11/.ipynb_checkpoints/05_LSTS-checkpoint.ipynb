{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b172a2-7cbf-4cfe-828c-70135f3675f0",
   "metadata": {},
   "source": [
    "# How to Generate Long-Short Trading Signals with a Random Forest\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2ffa13-43ae-4234-971c-973a85623d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Technical Analysis\n",
    "import talib\n",
    "\n",
    "# SciPy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "# OS & Time\n",
    "import sys, os\n",
    "from time import time\n",
    "from io import StringIO\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# StatsModel\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# LightBoosting Gradient\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239ee6aa-0301-422a-a74d-a3d805f91f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9466a747-78aa-49e0-b6a1-9a51275b0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fccff9b6-d9aa-4a3c-bd8d-6e76c5ac7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1c9e5f-e14d-412c-9438-b296917d165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ac0d3a-a9d4-4fac-a39f-8f00d9d98d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'return_predictions')\n",
    "\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf3f47-9acb-41bf-8373-0f62d6ab4b21",
   "metadata": {},
   "source": [
    "### Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc70524a-a50d-4912-b62f-ed71994edcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'stooq/japan/equities')\n",
    "\n",
    "data.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a60cb0-c7d2-4982-acc1-29026b9e4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.index.unique('ticker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabed69b-51f5-42ba-8839-a1256efe7ef6",
   "metadata": {},
   "source": [
    "#### Selecting Universe of 250 Most-Liquid Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaadc9c6-628b-4038-ab2c-b8b3996baeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = (pd.read_hdf(DATA_DIR / 'assets.h5', 'stooq/jp/tse/stocks/prices')\n",
    "          .loc[idx[:, '2010': '2017'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee08df1-a221-46cf-b354-77cd7342ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_vol = prices.close.mul(prices.volume)\n",
    "\n",
    "dollar_vol_rank = dollar_vol.groupby(level='date').rank(ascending=False)\n",
    "universe = dollar_vol_rank.groupby(level='ticker').mean().nsmallest(250).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38c00b-9f3b-4e5d-a897-0cffb5223aa4",
   "metadata": {},
   "source": [
    "### MultipleTimeSeriesCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f1275a-0710-4423-87a0-52f066805d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = MultipleTimeSeriesCV(n_splits=36,\n",
    "                          test_period_length=21,\n",
    "                          lookahead=5,\n",
    "                          train_period_length=2 * 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71778308-04d3-40cf-b21c-3051ba83642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(cv.split(X=data)):\n",
    "    train = data.iloc[train_idx]\n",
    "    train_dates = train.index.get_level_values('date')\n",
    "    test = data.iloc[test_idx]\n",
    "    test_dates = test.index.get_level_values('date')\n",
    "    df = train.reset_index().append(test.reset_index())\n",
    "    n = len(df)\n",
    "    assert n== len(df.drop_duplicates())\n",
    "    msg = f'Training: {train_dates.min().date()}-{train_dates.max().date()} '\n",
    "    msg += f' ({train.groupby(level=\"ticker\").size().value_counts().index[0]:,.0f} days) | '\n",
    "    msg += f'Test: {test_dates.min().date()}-{test_dates.max().date()} '\n",
    "    msg += f'({test.groupby(level=\"ticker\").size().value_counts().index[0]:,.0f} days)'\n",
    "    print(msg)\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53da9e-e4a5-4836-b4e9-13ffb6e89c3c",
   "metadata": {},
   "source": [
    "### Model Selection: Time Period and Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ca0153c-f4c8-4b90-a4d6-784d4c2995ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = data.loc[idx[universe, :'2017'], :]\n",
    "\n",
    "tickers = cv_data.index.unique('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea9e849d-7c56-40bb-80eb-c33c341f3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data.to_hdf('data.h5', 'stooq/japan/equities/cv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a29286-4396-45fc-b438-48b12368d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('data.h5') as store:\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c8e5074-1c06-451f-92dc-3572941df07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 10, 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b71787-5f06-4827-8a8f-a2112b6d93c0",
   "metadata": {},
   "source": [
    "### Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3814ac3f-f0fb-44b1-8df1-ef74e187aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d773ffb2-6fc1-4c72-852b-22137d09da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(cv_data.filter(like='fwd').columns)\n",
    "\n",
    "features = cv_data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3d952-39a9-45c3-aa58-e0e814641fcd",
   "metadata": {},
   "source": [
    "#### CV Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68b4fbf9-94a9-4329-bb01-4a9a87ee49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [5 * YEAR, 3 * YEAR, YEAR, 126, 63]\n",
    "\n",
    "test_lengths = [5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38442f70-17a5-46de-a524-3f4933e76372",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48df0ca0-0502-4be7-9f43-4f3885b9c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics = []\n",
    "\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'fwd_ret_{lookahead:02}'\n",
    "    df = cv_data.loc[:, features + [label]].dropna()\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([\n",
    "        lookahead, train_length, test_length,\n",
    "        np.mean(ic),\n",
    "        spearmanr(preds.y_true, preds.y_pred)[0]\n",
    "    ])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db305875-f7f0-4de2-a564-223d0a71b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9958a-b0a2-464f-a6c6-8f1054ed3f0e",
   "metadata": {},
   "source": [
    "### Information Coefficient Distribution by Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2690baad-b7b5-4a8d-8955-dca222c59550",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics_long = pd.concat([(lr_metrics.drop('ic', axis=1)\n",
    "                              .rename(columns={'ic_by_day': 'ic'})\n",
    "                              .assign(Measured='By Day')),\n",
    "                             lr_metrics.drop('ic_by_day', axis=1)\n",
    "                             .assign(Measured='Overall')])\n",
    "\n",
    "lr_metrics_long.columns=['Lookahead', 'Train Length', 'Test Length', 'IC', 'Measure']\n",
    "lr_metrics_long.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "114756d2-f7ea-41c5-97f2-1119d4b7b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Train Length',\n",
    "            y='IC',\n",
    "            hue='Test Length',\n",
    "            col='Lookahead',\n",
    "            row='Measure',\n",
    "            data=lr_metrics_long,\n",
    "            kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f40d215d-e47c-49a6-b8c9-1c5fb09deef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes =plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eae575-28b3-4a24-bc4c-6ab9f12aa68a",
   "metadata": {},
   "source": [
    "### Best Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf5a8ea0-d153-430e-8694-e41634df9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lr_metrics.groupby('lookahead', group_keys=False)\n",
    " .apply(lambda x: x.nlargest(3, 'ic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "088cc13a-743f-4ba7-a7b3-e5fcb6063621",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics.to_csv(results_path / 'lin_reg_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de577d2-f4b2-474b-9685-7fe6a5787d1f",
   "metadata": {},
   "source": [
    "## LightGBM Random Forest Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae05e184-636f-4e13-8f58-1ea7c77d9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(),\n",
    "                      index=model.feature_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62ec8d4c-d9da-4f27-a70b-5831299f17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = dict(boosting_type='rf',\n",
    "                   objective='regression',\n",
    "                   bagging_freq=1,\n",
    "                   verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d2ec9-277c-4840-8675-001987174939",
   "metadata": {},
   "source": [
    "#### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f69c00e-cf98-4e54-acef-a53c6fa74af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_fraction_opts = [.5, .75, .95]\n",
    "\n",
    "feature_fraction_opts = [.75, .95]\n",
    "\n",
    "min_data_in_leaf_opts = [250, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90b0a88c-c308-4cb8-b047-7bbb74f71ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = list(product(bagging_fraction_opts,\n",
    "                         feature_fraction_opts,\n",
    "                         min_data_in_leaf_opts))\n",
    "\n",
    "n_cv_params = len(cv_params)\n",
    "n_cv_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dfa160-5e60-492d-bbee-2b47976b30f9",
   "metadata": {},
   "source": [
    "#### Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "170d6fe5-79e7-4453-b082-08918a6fdfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proportion = .5\n",
    "sample_size = int(sample_proportion * n_cv_params)\n",
    "\n",
    "cv_param_sample = np.random.choice(list(range(n_cv_params)), \n",
    "                                     size=int(sample_size), \n",
    "                                     replace=False)\n",
    "\n",
    "cv_params_ = [cv_params[i] for i in cv_param_sample]\n",
    "print('# CV parameters:', len(cv_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da315d4c-ebfc-4779-8176-625ff91b47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = [25] + list(range(50, 501, 25))\n",
    "\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a39b4a-4bdc-45f3-be4f-1ba55fe29141",
   "metadata": {},
   "source": [
    "### Train/Test Period Lenghts\n",
    "\n",
    "#### Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b26deb3b-4d8b-4f0a-9d31-b44b6236b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [5 * YEAR, 3 * YEAR, YEAR, 126, 63]\n",
    "\n",
    "test_lengths = [5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35f4d72e-ef5b-43c5-8c03-5fc820c7c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = list(product(train_lengths, test_lengths))\n",
    "\n",
    "n_test_params = len(test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c01dc97-3197-4c85-a053-44d89f233dd1",
   "metadata": {},
   "source": [
    "#### Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82927d42-f895-4ff4-bbcb-b3e477fca947",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proportion = 1.0\n",
    "sample_size = int(sample_proportion * n_test_params)\n",
    "\n",
    "test_param_sample = np.random.choice(list(range(n_test_params)), \n",
    "                                     size=int(sample_size), \n",
    "                                     replace=False)\n",
    "\n",
    "test_params_ = [test_params[i] for i in test_param_sample]\n",
    "print('Train configs:', len(test_params_))\n",
    "print('CV Iterations:', len(cv_params_) * len(test_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c50abf-f08c-4a35-b740-aca94c6b66ff",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbbc7a84-7e18-4ab4-8367-0e758841ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['year', 'weekday', 'month']\n",
    "\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc7160-2c74-4c70-98f9-6adfef47b8ed",
   "metadata": {},
   "source": [
    "### Running Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8942462c-2f9e-41bf-8fda-8b36b3e26d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(cv_data.filter(like='fwd').columns)\n",
    "\n",
    "features = cv_data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfc83073-ff78-4843-9ecb-f2aabec3d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5037b9c6-bdb9-4d52-a9ab-c143fca267cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_store = Path(results_path / 'parameter_tuning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "356897f8-6113-4d5c-8e58-8cdbe99ecd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_cols = ['bagging_fraction',\n",
    "           'feature_fraction',\n",
    "           'min_data_in_leaf',\n",
    "           't'] + [str(n) for n in num_iterations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7846e8fd-27a7-4421-be5b-ab4365ac9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lookahead in lookaheads:\n",
    "    for train_length, test_length in test_params_:\n",
    "        n_splits = int(2 * YEAR / test_length)\n",
    "        print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | '\n",
    "              f'Test: {test_length:2.0f} | Params: {len(cv_params_):3.0f}')\n",
    "\n",
    "        cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                                  test_period_length=test_length,\n",
    "                                  train_period_length=train_length,\n",
    "                                  lookahead=lookahead)\n",
    "\n",
    "        label = label_dict[lookahead]\n",
    "        outcome_data = data.loc[:, features + [label]].dropna()\n",
    "\n",
    "        lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1),\n",
    "                               label=outcome_data[label],\n",
    "                               categorical_feature=categoricals,\n",
    "                               free_raw_data=False)\n",
    "        predictions, daily_ic, ic, feature_importance = [], [], [], []\n",
    "        key = f'{lookahead}/{train_length}/{test_length}'\n",
    "        T = 0\n",
    "        for p, (bagging_fraction, feature_fraction, min_data_in_leaf) in enumerate(cv_params_):\n",
    "            params = base_params.copy()\n",
    "            params.update(dict(bagging_fraction=bagging_fraction,\n",
    "                               feature_fraction=feature_fraction,\n",
    "                               min_data_in_leaf=min_data_in_leaf))\n",
    "\n",
    "            start = time()\n",
    "            cv_preds, nrounds = [], []\n",
    "            for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "                lgb_train = lgb_data.subset(used_indices=train_idx.tolist(), params=params).construct()\n",
    "                lgb_test = lgb_data.subset(used_indices=test_idx.tolist(), params=params).construct()\n",
    "\n",
    "                model = lgb.train(params=params,\n",
    "                                  train_set=lgb_train,\n",
    "                                  num_boost_round=num_boost_round,\n",
    "                                  verbose_eval=False)\n",
    "                if i == 0:\n",
    "                    fi = get_fi(model).to_frame()\n",
    "                else:\n",
    "                    fi[i] = get_fi(model)\n",
    "\n",
    "                test_set = outcome_data.iloc[test_idx, :]\n",
    "                X_test = test_set.loc[:, model.feature_name()]\n",
    "                y_test = test_set.loc[:, label]\n",
    "                y_pred = {str(n): model.predict(X_test, num_iteration=n)\n",
    "                          for n in num_iterations}\n",
    "                cv_preds.append(y_test.to_frame(\n",
    "                    'y_test').assign(**y_pred).assign(i=i))\n",
    "                nrounds.append(model.best_iteration)\n",
    "            feature_importance.append(fi.T.describe().T.assign(bagging_fraction=bagging_fraction,\n",
    "                                                               feature_fraction=feature_fraction,\n",
    "                                                               min_data_in_leaf=min_data_in_leaf))\n",
    "            cv_preds = pd.concat(cv_preds).assign(bagging_fraction=bagging_fraction,\n",
    "                                                  feature_fraction=feature_fraction,\n",
    "                                                  min_data_in_leaf=min_data_in_leaf)\n",
    "\n",
    "            predictions.append(cv_preds)\n",
    "            by_day = cv_preds.groupby(level='date')\n",
    "            ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test,\n",
    "                                                                    x[str(n)])[0]).to_frame(n)\n",
    "                                   for n in num_iterations], axis=1)\n",
    "\n",
    "            daily_ic.append(ic_by_day.assign(bagging_fraction=bagging_fraction,\n",
    "                                             feature_fraction=feature_fraction,\n",
    "                                             min_data_in_leaf=min_data_in_leaf))\n",
    "\n",
    "            cv_ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0]\n",
    "                  for n in num_iterations]\n",
    "\n",
    "            T += time() - start\n",
    "            ic.append([bagging_fraction, feature_fraction,\n",
    "                       min_data_in_leaf, lookahead] + cv_ic)\n",
    "\n",
    "            msg = f'{p:3.0f} | {format_time(T)} | '\n",
    "            msg += f'{bagging_fraction:3.0%} | {feature_fraction:3.0%} | {min_data_in_leaf:5,.0f} | '\n",
    "            msg += f'{max(cv_ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {ic_by_day.median().max(): 6.2%}'\n",
    "            print(msg)\n",
    "\n",
    "        m = pd.DataFrame(ic, columns=ic_cols)\n",
    "        m.to_hdf(cv_store, 'ic/' + key)\n",
    "        pd.concat(daily_ic).to_hdf(cv_store, 'daily_ic/' + key)\n",
    "        pd.concat(feature_importance).to_hdf(cv_store, 'fi/' + key)\n",
    "        pd.concat(predictions).to_hdf(cv_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa1c48-ccf9-4c6c-8a69-4cea7abd2dac",
   "metadata": {},
   "source": [
    "### Analyse Cross-Validation Results\n",
    "\n",
    "#### Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84896abd-1ee0-4c23-91b0-dc01067727bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = ['train_length',\n",
    "           'test_length',\n",
    "           'bagging_fraction',\n",
    "           'feature_fraction',\n",
    "           'min_data_in_leaf',\n",
    "           't', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "659bf3b4-cce9-4e6d-8541-0215d0c4ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ic, ic = [], []\n",
    "\n",
    "for t in lookaheads:\n",
    "    print(t)\n",
    "    with pd.HDFStore(cv_store) as store:\n",
    "        keys = [k[1:] for k in store.keys() if k.startswith(f'/fi/{t}')]\n",
    "        for key in keys:\n",
    "            train_length, test_length = key.split('/')[2:]\n",
    "            print(train_length, test_length)\n",
    "            k = f'{t}/{train_length}/{test_length}'\n",
    "            cols = {'t': t,\n",
    "                    'train_length': int(train_length),\n",
    "                    'test_length': int(test_length)}\n",
    "\n",
    "            ic.append(pd.melt(store['ic/' + k]\n",
    "                              .assign(**cols),\n",
    "                              id_vars=id_vars[:-1],\n",
    "                              value_name='ic',\n",
    "                              var_name='rounds')\n",
    "                      .apply(pd.to_numeric))\n",
    "\n",
    "            df = store['daily_ic/' + k].assign(**cols).reset_index()\n",
    "            daily_ic.append(pd.melt(df,\n",
    "                                    id_vars=id_vars,\n",
    "                                    value_name='daily_ic',\n",
    "                                    var_name='rounds')\n",
    "                            .set_index('date')\n",
    "                            .apply(pd.to_numeric)\n",
    "                            .reset_index())            \n",
    "\n",
    "ic = pd.concat(ic, ignore_index=True)\n",
    "\n",
    "daily_ic = pd.concat(daily_ic, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad3937-35d5-40db-b246-d425e991d5ef",
   "metadata": {},
   "source": [
    "### Predictive Performance: CV Information Coefficient by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39835f1f-0bfd-40ff-ab9d-51cfcc98b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['t','train_length', 'test_length', \n",
    "              'bagging_fraction', 'feature_fraction', 'min_data_in_leaf']\n",
    "\n",
    "daily_ic_avg = daily_ic.groupby(group_cols + ['rounds']).daily_ic.mean().to_frame('ic').reset_index()\n",
    "daily_ic_avg.groupby('t', group_keys=False).apply(lambda x: x.nlargest(3, 'ic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "614e7460-6526-4240-94c4-acf5457b356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ic_avg.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbf84bf0-ad00-4ba7-bc71-9168978e6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxenplot(x='t', y='ic', data=daily_ic_avg)\n",
    "ax.axhline(0, ls='--', lw=1, c='k');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2264ef8f-2bf0-4bff-96f2-46020df97252",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='t',\n",
    "                y='ic',\n",
    "                col='train_length',\n",
    "                row='test_length',\n",
    "                data=daily_ic_avg[(daily_ic_avg.test_length == 21)],\n",
    "                kind='boxen')\n",
    "\n",
    "g.savefig(results_path / 'daily_ic_test_21', dpi=300);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec7656-b703-409d-b29e-7950a5e05f00",
   "metadata": {},
   "source": [
    "### HyperParameter Impact: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa323c6c-58e0-4f29-978e-62074067d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = {}\n",
    "\n",
    "for t in [1, 5]:\n",
    "    df_ = daily_ic_avg[(daily_ic_avg.t==t)&(daily_ic_avg.rounds<=250)].dropna()\n",
    "    y, X = df_.ic, df_.drop(['ic', 't'], axis=1)\n",
    "    X = sm.add_constant(pd.get_dummies(X, columns=X.columns, drop_first=True))\n",
    "    model = sm.OLS(endog=y, exog=X)\n",
    "    lin_reg[t] = model.fit()\n",
    "    s = lin_reg[t].summary()\n",
    "    coefs = pd.read_csv(StringIO(s.tables[1].as_csv())).rename(\n",
    "        columns=lambda x: x.strip())\n",
    "    coefs.columns = ['variable', 'coef', 'std_err',\n",
    "                     't', 'p_value', 'ci_low', 'ci_high']\n",
    "    coefs.to_csv(results_path / f'lr_result_{t:02}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cee90070-2eba-48ee-96ff-3cda891e8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lr_result(model, ax):\n",
    "    ci = model.conf_int()\n",
    "    errors = ci[1].sub(ci[0]).div(2)\n",
    "\n",
    "    coefs = (model.params.to_frame('coef').assign(error=errors)\n",
    "             .reset_index().rename(columns={'index': 'variable'}))\n",
    "    coefs = coefs[~coefs['variable'].str.startswith(\n",
    "        'date') & (coefs.variable != 'const')]\n",
    "    coefs.variable = coefs.variable.str.split('_').str[-1]\n",
    "\n",
    "    coefs.plot(x='variable', y='coef', kind='bar', ax=ax, \n",
    "               color='none', capsize=3, yerr='error', legend=False, rot=0)    \n",
    "    ax.set_ylabel('IC')\n",
    "    ax.set_xlabel('')\n",
    "    ax.scatter(x=pd.np.arange(len(coefs)), marker='_', s=120, y=coefs['coef'], color='black')\n",
    "    ax.axhline(y=0, linestyle='--', color='black', linewidth=1)\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "\n",
    "    ax.annotate('Train\\nLength', xy=(.09, -0.1), xytext=(.09, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=5, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "    ax.annotate('Test\\nLength', xy=(.23, -0.1), xytext=(.23, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=2, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "    ax.annotate('Bagging\\nFraction', xy=(.32, -0.1), xytext=(.32, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=2.7, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "\n",
    "    ax.annotate('Feature\\nFraction', xy=(.44, -0.1), xytext=(.44, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=3.4, lengthB=1.0', lw=1.0, color='black'))\n",
    "    \n",
    "\n",
    "    ax.annotate('Min.\\nSamples', xy=(.55, -0.1), xytext=(.55, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=2.5, lengthB=1.0', lw=1.0, color='black'))    \n",
    "    \n",
    "    ax.annotate('Number of\\nRounds', xy=(.8, -0.1), xytext=(.8, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=11.2, lengthB=1.0', lw=1.0, color='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ea49d03-fe9d-494e-9a91-6c43db5d798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n",
    "    axes = axes.flatten()\n",
    "    for i, t in enumerate([1, 5]):\n",
    "        visualize_lr_result(lin_reg[t], axes[i])\n",
    "        axes[i].set_title(f'Lookahead: {t} Day(s)')\n",
    "    fig.suptitle('OLS Coefficients & Confidence Intervals', fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=.92)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2214ded-9fe2-4e12-bb85-70f2d2703418",
   "metadata": {},
   "source": [
    "### Information Coefficient: Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2906b1e-17de-4efe-9caa-484ca730357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f10981-b4aa-4bb3-a132-37ca8741f108",
   "metadata": {},
   "source": [
    "#### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acb25231-310f-4b56-8207-85b984baf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.groupby('t').apply(lambda x: x.nlargest(3, 'ic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1744a-5b42-4c83-9433-c50642eedd5b",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23f70233-a082-424a-80f5-15f2e8822ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='t',\n",
    "                y='ic',\n",
    "                col='train_length',\n",
    "                row='test_length',\n",
    "                data=ic[(ic.test_length == 21) & (ic.t < 21)],\n",
    "                kind='box')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab68af89-c17d-46f8-86a1-edc7ec6af1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "\n",
    "train_length = 756\n",
    "\n",
    "test_length = 21\n",
    "\n",
    "g = sns.catplot(x='rounds',\n",
    "    y='ic',\n",
    "    col='feature_fraction',\n",
    "    hue='bagging_fraction',\n",
    "    row='min_data_in_leaf',\n",
    "    data=ic[(ic.t == t) &\n",
    "            (ic.train_length == train_length) &\n",
    "            (ic.test_length == test_length)],\n",
    "    kind='swarm');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21789923-0bb7-4241-994c-c58d3455e3e3",
   "metadata": {},
   "source": [
    "### Random Forest vs Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34477f77-ce9a-4b15-abfd-d2be95565864",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_metrics = pd.read_csv(results_path / 'lin_reg_performance.csv')\n",
    "\n",
    "lr_metrics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4fc22650-6d0c-4c82-b111-58d38a4c7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ic_avg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ca947ff-9c6c-42b0-b133-39421ba14cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    ax = (ic.groupby('t').ic.max().to_frame('Random Forest')\n",
    "     .join(lr_metrics.groupby('lookahead').ic.max().to_frame('Linear Regression')).plot.barh())\n",
    "    ax.set_ylabel('Lookahead')\n",
    "    ax.set_xlabel('Information Coefficient')\n",
    "    sns.despine()\n",
    "    plt.tight_layout();\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700ed21-e19a-4d3e-b25b-1002151c9612",
   "metadata": {},
   "source": [
    "### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "435b7fb8-8542-4294-8e03-967b0a5b3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols = ['train_length', 'test_length', 'bagging_fraction',\n",
    "              'feature_fraction', 'min_data_in_leaf', 'rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d42fc2bd-4d18-4f1a-8a3d-7aeb8185ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(data, t=5, best=0):\n",
    "    df = data[data.t == t].sort_values('ic', ascending=False).iloc[best]\n",
    "    df = df.loc[param_cols]\n",
    "    rounds = int(df.rounds)\n",
    "    params = pd.to_numeric(df.drop('rounds'))\n",
    "    return params, rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51b6f2ca-ce82-47db-8ed3-2deb2d69181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = dict(boosting_type='rf',\n",
    "                   objective='regression',\n",
    "                   bagging_freq=1,\n",
    "                   verbose=-1)\n",
    "\n",
    "store = Path(results_path / 'predictions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2cd32430-be36-48de-bd6b-125460e2ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lookahead in [1, 5, 10, 21]:\n",
    "    if lookahead > 1: \n",
    "        continue\n",
    "    print(f'\\nLookahead: {lookahead:02}')\n",
    "    data = (pd.read_hdf('data.h5', 'stooq/japan/equities'))\n",
    "    labels = sorted(data.filter(like='fwd').columns)\n",
    "    features = data.columns.difference(labels).tolist()\n",
    "    label = f'fwd_ret_{lookahead:02}'\n",
    "    data = data.loc[:, features + [label]].dropna()\n",
    "\n",
    "    categoricals = ['year', 'weekday', 'month']\n",
    "    for feature in categoricals:\n",
    "        data[feature] = pd.factorize(data[feature], sort=True)[0]\n",
    "\n",
    "    lgb_data = lgb.Dataset(data=data[features],\n",
    "                           label=data[label],\n",
    "                           categorical_feature=categoricals,\n",
    "                           free_raw_data=False)\n",
    "    \n",
    "    for position in range(10):\n",
    "        params, num_boost_round = get_params(daily_ic_avg,\n",
    "                                             t=lookahead,\n",
    "                                             best=position)\n",
    "        params = params.to_dict()\n",
    "        params['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
    "        train_length = int(params.pop('train_length'))\n",
    "        test_length = int(params.pop('test_length'))\n",
    "        params.update(base_params)\n",
    "\n",
    "        print(f'\\tPosition: {position:02}')\n",
    "\n",
    "        n_splits = int(2 * YEAR / test_length)\n",
    "        cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                                  test_period_length=test_length,\n",
    "                                  lookahead=lookahead,\n",
    "                                  train_period_length=train_length)\n",
    "\n",
    "        predictions = []\n",
    "        start = time()\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "            train_set = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                        params=params).construct()\n",
    "    \n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=train_set,\n",
    "                              num_boost_round=num_boost_round,\n",
    "                              verbose_eval=False)\n",
    "\n",
    "            test_set = data.iloc[test_idx, :]\n",
    "            y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "            y_pred = model.predict(test_set.loc[:, model.feature_name()])\n",
    "            predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "        if position == 0:\n",
    "            test_predictions = (pd.concat(predictions)\n",
    "                                .rename(columns={'prediction': position}))\n",
    "        else:\n",
    "            test_predictions[position] = pd.concat(predictions).prediction\n",
    "        \n",
    "\n",
    "    by_day = test_predictions.groupby(level='date')\n",
    "    for position in range(10):\n",
    "        if position == 0:\n",
    "            ic_by_day = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0]).to_frame()\n",
    "        else:\n",
    "            ic_by_day[position] = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "\n",
    "    test_predictions.to_hdf(store, f'test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34c211-ab2a-4225-9e86-c0fa29dcc52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
