{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c74768-4e6b-4ec8-8e5f-0bbb5e5e62f9",
   "metadata": {},
   "source": [
    "# RNN & Word Embeddings for SEC Filings to Predict Returns\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0aa1c557-3d4f-406f-8e27-ee9b38a5043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "\n",
    "# Path, Time & Collection\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm import tqdm \n",
    "\n",
    "# SciPy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# yFinance\n",
    "import yfinance as yf\n",
    "\n",
    "# Gensim\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (Dense, GRU, Bidirectional,\n",
    "                                     Embedding, BatchNormalization, Dropout)\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "71e3ea4f-647e-45d7-9ef2-4f3c1de78eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5edbcbd0-d4f8-4b0b-a6b3-023bef6bdb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "efb579e1-5a6c-4961-946a-def8906687fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f'{h:02.0f}:{m:02.0f}:{s:02.0f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "58c2592c-a859-4ee1-83cb-e389061acbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = np.arange(.1, 1, .1).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884273b-4078-48a9-a6ab-8d16187c58d2",
   "metadata": {},
   "source": [
    "### Getting Stock Price Data\n",
    "\n",
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79086ec9-e702-47a7-aaea-64110375b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('..', 'data', 'sec-filings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f8840-ace4-4741-86a0-0560efed8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results', 'sec-filings')\n",
    "\n",
    "selected_section_path = results_path / 'ngrams_1'\n",
    "ngram_path = results_path / 'ngrams'\n",
    "vector_path = results_path / 'vectors'\n",
    "\n",
    "for path in [vector_path, selected_section_path, ngram_path]:\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c95055-b4be-49f3-8ecd-5d465e01784a",
   "metadata": {},
   "source": [
    "#### Getting Filing Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68793469-2d9c-4a58-8648-ced1c2117e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_index = (pd.read_csv(data_path / 'filing_index.csv',\n",
    "                            parse_dates=['DATE_FILED'])\n",
    "                .rename(columns=str.lower))\n",
    "\n",
    "filing_index.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850ea2d-6c4c-4741-bf10-7c1bf6dd1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_index.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c705a1-f514-4006-b909-4d1739867620",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72f7488-5e8c-431a-bb8f-6c5c53ea85dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_index.ticker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0566d-51d2-440e-a932-b9b04d500a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_index.date_filed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243a65d-8ca9-4205-b4e7-f645e5c78206",
   "metadata": {},
   "source": [
    "#### Downloading Stock Price Data using Yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dc1fa-64e4-48a6-830f-c5aeeca05f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_data, missing = [], []\n",
    "\n",
    "for i, (symbol, dates) in enumerate(filing_index.groupby('ticker').date_filed, 1):\n",
    "    \n",
    "    if i % 250 == 0:\n",
    "        print(i, len(yf_data), len(set(missing)), flush=True)\n",
    "    \n",
    "    ticker = yf.Ticker(symbol)\n",
    "    for filing, date in dates.to_dict().items():\n",
    "        start = date - timedelta(days=93)\n",
    "        end = date + timedelta(days=31)\n",
    "        df = ticker.history(start=start, end=end)\n",
    "        if df.empty:\n",
    "            missing.append(symbol)\n",
    "        else:\n",
    "            yf_data.append(df.assign(ticker=symbol, filing=filing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b80c7-45fb-439a-8898-7badd6436476",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_data = pd.concat(yf_data).rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f1e84-7db2-4c98-9451-78606e42e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_data.to_hdf(results_path / 'sec_returns.h5', 'data/yfinance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad7c8c-81a6-4506-80fe-8cbbc05c9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_data = pd.read_hdf(results_path / 'sec_returns.h5', 'data/yfinance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f863e2-752e-4188-97b4-dd7a13e82a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_data.ticker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7936c39-1dca-458e-a5f2-a4984d5217bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61fcab-c66c-48c4-9812-dc25a8b1488f",
   "metadata": {},
   "source": [
    "#### Getting (some) Missing Prices from `Quandl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3570f-0a3f-4b1f-bc16-886be21d79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do = (filing_index.loc[~filing_index.ticker.isin(yf_data.ticker.unique()), \n",
    "                          ['ticker', 'date_filed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a238720-d409-4d8e-a4cc-71aa4cf940a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do.date_filed.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01e98b-c671-48f4-b744-a2babfa8dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl_tickers = (pd.read_hdf('../data/assets.h5', 'quandl/wiki/prices')\n",
    "                  .loc[idx['2012':, :], :]\n",
    "                  .index.unique('ticker'))\n",
    "\n",
    "quandl_tickers = list(set(quandl_tickers).intersection(set(to_do.ticker)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3884ba2-e063-469b-a962-60798fa0e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quandl_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a60a0-3241-403d-9ddf-f0ef2f73b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do = filing_index.loc[filing_index.ticker.isin(quandl_tickers), ['ticker', 'date_filed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eef856-b509-44b7-8688-2908de849328",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ceaf1-5819-4e5c-80e1-202bc777e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv = ['adj_open', 'adj_high', 'adj_low', 'adj_close', 'adj_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59b4ef-237b-4c7c-a7e9-290e5fb81bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl = (pd.read_hdf('../data/assets.h5', 'quandl/wiki/prices')\n",
    "          .loc[idx['2012': , quandl_tickers], ohlcv]\n",
    "          .rename(columns=lambda x: x.replace('adj_', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c99be-79a9-4920-96ca-80d5fe16719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0ab71-8b90-4f1f-9622-3540b7b4aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl_data = []\n",
    "\n",
    "for i, (symbol, dates) in enumerate(to_do.groupby('ticker').date_filed, 1):\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ', flush=True)\n",
    "    for filing, date in dates.to_dict().items():\n",
    "        start = date - timedelta(days=93)\n",
    "        end = date + timedelta(days=31)\n",
    "        quandl_data.append(quandl.loc[idx[start:end, symbol], :].reset_index('ticker').assign(filing=filing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50035e-986d-4f4a-89e6-95624a9dc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl_data.to_hdf(results_path / 'sec_returns.h5', 'data/quandl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22dd254-edd9-477b-b394-a67c4be0c75c",
   "metadata": {},
   "source": [
    "### Combining, Cleaning & Persisting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f703c-3f63-43f6-8827-ce76adabcf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_hdf(results_path / 'sec_returns.h5', 'data/yfinance')\n",
    "        .drop(['dividends', 'stock splits'], axis=1)\n",
    "        .append(pd.read_hdf(results_path / 'sec_returns.h5',\n",
    "                            'data/quandl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef752a-ae03-411a-b9fa-3e2459be52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:, ['filing', 'ticker', 'open', 'high', 'low', 'close', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f20ae-43ea-46cb-b668-469087a57016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20acd20-c574-4e6f-b336-5a1cf0a55ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['filing', 'ticker']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec69ca0-c98a-4471-afc7-f90ad8336830",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf(results_path / 'sec_returns.h5', 'prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce72b81-1f4d-4f15-9307-9c3c615612a8",
   "metadata": {},
   "source": [
    "### Copying Filings with Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303199a3-f5a1-475e-981f-bcac506e4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf(results_path / 'sec_returns.h5', 'prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29650bb-2557-4bfa-9842-28f8157bf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_with_data = data.filing.unique()\n",
    "\n",
    "len(filings_with_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f1ad8-44d8-48af-a41e-8dda4851afce",
   "metadata": {},
   "source": [
    "#### Removing Short & Long Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc1f0a-be62-49d6-b6e9-baab5baa2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentence_length = 5\n",
    "\n",
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6782a7-fabc-469c-b5b7-2b947d383187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length = Counter()\n",
    "\n",
    "for i, idx in enumerate(filings_with_data, 1):\n",
    "    if i % 500 == 0:\n",
    "        print(i, end=' ', flush=True)\n",
    "    text = pd.read_csv(data_path / 'selected_sections' / f'{idx}.csv').text\n",
    "    sent_length.update(text.str.split().str.len().tolist())\n",
    "    text = text[text.str.split().str.len().between(min_sentence_length, max_sentence_length)]\n",
    "    text = '\\n'.join(text.tolist())\n",
    "    with (selected_section_path / f'{idx}.txt').open('w') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daebf3e8-ffe7-4e19-8558-8adb0babf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length = pd.Series(dict(sent_length.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c2761-6f3b-4a20-89e2-ff991131b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    sent_length.sort_index().cumsum().div(sent_length.sum()).loc[5:51].plot.bar(figsize=(12, 4), rot=0)\n",
    "    sns.despine();\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff85d8-28a7-4470-95ba-8c82df2ee140",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    sent_length.sort_index().loc[:50].plot.bar(figsize=(14, 4))\n",
    "    sns.despine();\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4d87e-7989-41dd-99ba-f9122299dd38",
   "metadata": {},
   "source": [
    "### Creating Bi & trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1c1f6-289b-4c2d-a0c9-e797b31cb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = selected_section_path.glob('*.txt')\n",
    "\n",
    "texts = [f.read_text() for f in files]\n",
    "\n",
    "unigrams = ngram_path / 'ngrams_1.txt'\n",
    "unigrams.write_text('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da800a2f-86ad-4577-8111-348b96dbdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = unigrams.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01550b-aefd-4d5c-bf5b-d9fba2123acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = []\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i, n in enumerate([2, 3]):\n",
    "    sentences = LineSentence(ngram_path / f'ngrams_{n-1}.txt')\n",
    "    phrases = Phrases(sentences=sentences,\n",
    "                      min_count=25,  # ignore terms with a lower count\n",
    "                      threshold=0.5,  # accept phrases with higher score\n",
    "                      max_vocab_size=4000000,  # prune of less common words to limit memory use\n",
    "                      delimiter=b'_',  # how to join ngram tokens\n",
    "                      scoring='npmi')\n",
    "\n",
    "    s = pd.DataFrame([[k.decode('utf-8'), v] for k, v in phrases.export_phrases(sentences)], \n",
    "                     columns=['phrase', 'score']).assign(length=n)\n",
    "\n",
    "    n_grams.append(s.groupby('phrase').score.agg(['mean', 'size']))\n",
    "    print(n_grams[-1].nlargest(5, columns='size'))\n",
    "    \n",
    "    grams = Phraser(phrases)\n",
    "    sentences = grams[sentences]\n",
    "    (ngram_path / f'ngrams_{n}.txt').write_text('\\n'.join([' '.join(s) for s in sentences]))\n",
    "    \n",
    "    src_dir = results_path / f'ngrams_{n-1}'\n",
    "    target_dir = results_path / f'ngrams_{n}'\n",
    "    if not target_dir.exists():\n",
    "        target_dir.mkdir()\n",
    "    \n",
    "    for f in src_dir.glob('*.txt'):\n",
    "        text = LineSentence(f)\n",
    "        text = grams[text]\n",
    "        (target_dir / f'{f.stem}.txt').write_text('\\n'.join([' '.join(s) for s in text]))\n",
    "    print('\\n\\tDuration: ', format_time(time() - start))\n",
    "\n",
    "n_grams = pd.concat(n_grams).sort_values('size', ascending=False)          \n",
    "n_grams.to_parquet(results_path / 'ngrams.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8927d9-6279-423b-8f86-8f2cf52b3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams.groupby(n_grams.index.str.replace('_', ' ').str.count(' ')).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e04ca-84f8-4929-a527-a689b7c9478d",
   "metadata": {},
   "source": [
    "### Converting Filings to Integer Sequences Based on Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd149ff7-6de2-4ad1-b0c8-dc442ba3f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = (ngram_path / 'ngrams_3.txt').read_text().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6b59e-3394-4c23-b5b9-b14a372ff703",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c5141-6f21-4501-bbf7-d7a5326091db",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cnt = Counter()\n",
    "\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    if i % 500000 == 0:\n",
    "        print(f'{i/n:.1%}', end=' ', flush=True)\n",
    "    token_cnt.update(sentence.split())\n",
    "\n",
    "token_cnt = pd.Series(dict(token_cnt.most_common()))\n",
    "token_cnt = token_cnt.reset_index()\n",
    "token_cnt.columns = ['token', 'n']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e52141-4228-4f42-b615-3774b5f843ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cnt.to_parquet(results_path / 'token_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2effb1f-3676-4345-b6c2-49a19410506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cnt.n.describe(deciles).apply(lambda x: f'{x:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f5f7a-f1b4-46cf-bc93-9031cc75c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cnt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8e761-6b3c-405a-9619-232c62a7271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cnt.nlargest(10, columns='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e62835-dc45-41da-beb9-022604dd0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cnt.sort_values(by=['n', 'token'], ascending=[False, True]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6ef50-54c7-44bc-b3f7-e2e8c321c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_by_freq = token_cnt.sort_values(by=['n', 'token'], ascending=[False, True]).token\n",
    "\n",
    "token2id = {token: i for i, token in enumerate(token_by_freq, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c46b6-f163-4fe4-9aac-bb5cb9cfb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa60c6-8a17-4172-91ef-1de95e420a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, i in token2id.items():\n",
    "    print(token, i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96f8ad-52ed-4bdd-95b3-1871aa3e2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(min_len=100, max_len=20000, num_words=25000, oov_char=2):\n",
    "    if not vector_path.exists():\n",
    "        vector_path.mkdir()\n",
    "    seq_length = {}\n",
    "    skipped = 0\n",
    "    for i, f in tqdm(enumerate((results_path / 'ngrams_3').glob('*.txt'), 1)):\n",
    "        file_id = f.stem\n",
    "        text = f.read_text().split('\\n')\n",
    "        vector = [token2id[token] if token2id[token] + 2 < num_words else oov_char \n",
    "                  for line in text \n",
    "                  for token in line.split()]\n",
    "        vector = vector[:max_len]\n",
    "        if len(vector) < min_len:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        seq_length[int(file_id)] = len(vector)\n",
    "        np.save(vector_path / f'{file_id}.npy', np.array(vector))\n",
    "    seq_length = pd.Series(seq_length)\n",
    "    return seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cf499-84ed-4807-a448-666a2d611fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9ebbf-3d9a-4cec-93fe-aad5ec688385",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seq_length).to_csv(results_path / 'seq_length.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1233dc-335e-4388-8947-e0270c925950",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length.describe(deciles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029ff9f-7b73-441e-985f-60bc69150f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66af83-e78b-4e24-b783-4ad25b334195",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(18,5))\n",
    "token_cnt.n.plot(logy=True, logx=True, ax=axes[0], title='Token Frequency (log-log scale)')\n",
    "sent_length.sort_index().loc[:50].plot.bar(ax=axes[1], rot=0, title='Sentence Length')\n",
    "\n",
    "n=5\n",
    "ticks = axes[1].xaxis.get_ticklocs()\n",
    "ticklabels = [l.get_text() for l in axes[1].xaxis.get_ticklabels()]\n",
    "axes[1].xaxis.set_ticks(ticks[n-1::n])\n",
    "axes[1].xaxis.set_ticklabels(ticklabels[n-1::n])\n",
    "axes[1].set_xlabel('Sentence Length')\n",
    "\n",
    "sns.distplot(seq_length, ax=axes[2], bins=50)\n",
    "axes[0].set_ylabel('Token Frequency')\n",
    "axes[0].set_xlabel('Token ID')\n",
    "\n",
    "axes[2].set_xlabel('# Words per Filing')\n",
    "axes[2].set_title('Filing Length Distribution')\n",
    "\n",
    "fig.suptitle('Corpus Stats', fontsize=13)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.85)\n",
    "fig.savefig(results_path / 'sec_seq_len', dpi=300);\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5ff72-c369-4b8e-8ae1-34e796778ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = vector_path.glob('*.npy')\n",
    "\n",
    "filings = sorted([int(f.stem) for f in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe111dd-e9ae-476b-8288-25f9bd298305",
   "metadata": {},
   "source": [
    "### Prepare Model Data\n",
    "\n",
    "### Creating Weekly Forward Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb34aa-1222-4c79-82d0-e678b966bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_hdf(results_path / 'sec_returns.h5', 'prices')\n",
    "\n",
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b628a-1eda-4130-9751-20366dcbfd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_return = {}\n",
    "\n",
    "for filing in filings:\n",
    "    date_filed = filing_index.at[filing, 'date_filed']\n",
    "    price_data = prices[prices.filing==filing].close.sort_index()\n",
    "    \n",
    "    try:\n",
    "        r = (price_data\n",
    "             .pct_change(periods=5)\n",
    "             .shift(-5)\n",
    "             .loc[:date_filed]\n",
    "             .iloc[-1])\n",
    "    except:\n",
    "        continue\n",
    "    if not np.isnan(r) and -.5 < r < 1:\n",
    "        fwd_return[filing] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32685000-37ea-4a81-b6d2-afa7438db1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fwd_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e355ec-3c54-4492-8c0d-018cb62ac8a1",
   "metadata": {},
   "source": [
    "#### Combining Returns with Filing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9308b53-eae2-43af-b7d9-54a623f94f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = [], []\n",
    "\n",
    "for filing_id, fwd_ret in fwd_return.items():\n",
    "    X.append(np.load(vector_path / f'{filing_id}.npy') + 2)\n",
    "    y.append(fwd_ret)\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e6e51-d8ee-4bf0-a968-fa4f75b9c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf01c9-fc17-4d17-8667-2491e606a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443e227-4475-48ea-aa96-ba57a3ad97ee",
   "metadata": {},
   "source": [
    "### Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264e90a-22c9-42dc-9794-158abbc5df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2698d-b806-4c76-9796-6162b195510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, \n",
    "                        truncating='pre', \n",
    "                        padding='pre', \n",
    "                        maxlen=maxlen)\n",
    "\n",
    "X_test = pad_sequences(X_test, \n",
    "                       truncating='pre', \n",
    "                       padding='pre', \n",
    "                       maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00d984-158e-48bc-8f90-e201dbb26af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23161599-f61f-42a4-a959-3ecde869db2c",
   "metadata": {},
   "source": [
    "### Defining Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78187576-9f4a-4702-82bf-abe79f3d5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c02a8-391a-4093-9434-b96ab507836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d62bf9-6dd1-4f7c-b319-7f338c874c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f3199f-3e0e-4980-a02a-4afc9090749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential([\n",
    "    Embedding(input_dim=input_dim, \n",
    "              output_dim=embedding_size, \n",
    "              input_length=maxlen,\n",
    "             name='EMB'),\n",
    "    BatchNormalization(name='BN1'),\n",
    "    Bidirectional(GRU(32), name='BD1'),\n",
    "    BatchNormalization(name='BN2'),\n",
    "    Dropout(.1, name='DO1'),\n",
    "    Dense(5, name='D'),\n",
    "    Dense(1, activation='linear', name='OUT')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ed0f6-f345-4494-aa12-afeb31cbfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2315060a-df07-4391-a26e-5d06a74651ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(loss='mse', \n",
    "            optimizer='Adam',\n",
    "            metrics=[RootMeanSquaredError(name='RMSE'),\n",
    "                     MeanAbsoluteError(name='MAE')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb6f2e-4e36-4ad7-ba6d-ebfc9b14f91b",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8545d46-e877-4c1b-a2ee-eac2786d5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_MAE', \n",
    "                               patience=5,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a05010-99bb-46c2-823e-c09e8beae8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = rnn.fit(X_train,\n",
    "                   y_train,\n",
    "                   batch_size=32,\n",
    "                   epochs=100,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks=[early_stopping],\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d84ac-0543-430e-b1db-112c8f4a8b7f",
   "metadata": {},
   "source": [
    "### Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12450e99-dbe6-4805-90e8-3f016ab759e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(training.history)\n",
    "\n",
    "df.to_csv(results_path / 'rnn_sec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44122009-9c0e-4f33-99f2-ffdd2e2679fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd405a-fbac-40dd-831d-47e9c7f42f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 4), sharey=True)\n",
    "plot_data = (df[['RMSE', 'val_RMSE']].rename(columns={'RMSE': 'Training', \n",
    "                                                      'val_RMSE': 'Validation'}))\n",
    "plot_data.plot(ax=axes[0], title='Root Mean Squared Error')\n",
    "\n",
    "plot_data = (df[['MAE', 'val_MAE']].rename(columns={'MAE': 'Training', \n",
    "                                                    'val_MAE': 'Validation'}))\n",
    "plot_data.plot(ax=axes[1], title='Mean Absolute Error')\n",
    "\n",
    "for i in [0, 1]:\n",
    "    axes[i].set_xlim(1, 10)\n",
    "    axes[i].set_xlabel('Epoch')\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'sec_cv_performance', dpi=300);\n",
    "plt.grid()\n",
    "plt.show(0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f1d4b-8b61-40a6-886c-03d52065a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = rnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a183e9a-a144-44fe-beec-bf968700f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, p = spearmanr(y_score.squeeze(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984f316-7c6e-44ae-9639-f173de093186",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Information Coefficient: {rho*100:.2f} ({p:.2%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38907fea-9923-40a5-9d80-170b748b36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(y_score.squeeze(), y_test, kind='reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddc8ac-386f-4e28-8186-b75d7d774593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLAT] *",
   "language": "python",
   "name": "conda-env-MLAT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
