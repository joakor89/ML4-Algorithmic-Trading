{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f8910b-17e3-4f68-9026-ac7c120d79e7",
   "metadata": {},
   "source": [
    "# Predicting Stock Price Moves with Logistic Regression\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78dbfa6-96d3-4263-9922-c97c36d4c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS\n",
    "import sys, os\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "\n",
    "# Time\n",
    "from time import time\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# SciPy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Data Manipulation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25182bd5-9dac-4688-8a59-7738cbfc34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f270d77-a913-49ce-89a0-cfb7caa869ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54cee27-d6b5-443f-a4c6-f0bf3395807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import MultipleTimeSeriesCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856e1e60-c87d-4e09-8075-f91875e405b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleTimeSeriesCV:\n",
    "    \"\"\"Generates tuples of train_idx, test_idx pairs\n",
    "    Assumes the MultiIndex contains levels 'symbol' and 'date'\n",
    "    purges overlapping outcomes\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_splits=3,\n",
    "                 train_period_length=126,\n",
    "                 test_period_length=21,\n",
    "                 lookahead=None,\n",
    "                 date_idx='date',\n",
    "                 shuffle=False):\n",
    "        self.n_splits = n_splits\n",
    "        self.lookahead = lookahead\n",
    "        self.test_length = test_period_length\n",
    "        self.train_length = train_period_length\n",
    "        self.shuffle = shuffle\n",
    "        self.date_idx = date_idx\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        unique_dates = X.index.get_level_values(self.date_idx).unique()\n",
    "        days = sorted(unique_dates, reverse=True)\n",
    "        split_idx = []\n",
    "        for i in range(self.n_splits):\n",
    "            test_end_idx = i * self.test_length\n",
    "            test_start_idx = test_end_idx + self.test_length\n",
    "            train_end_idx = test_start_idx + self.lookahead - 1\n",
    "            train_start_idx = train_end_idx + self.train_length + self.lookahead - 1\n",
    "            split_idx.append([train_start_idx, train_end_idx,\n",
    "                              test_start_idx, test_end_idx])\n",
    "\n",
    "        dates = X.reset_index()[[self.date_idx]]\n",
    "        for train_start, train_end, test_start, test_end in split_idx:\n",
    "\n",
    "            train_idx = dates[(dates[self.date_idx] > days[train_start])\n",
    "                              & (dates[self.date_idx] <= days[train_end])].index\n",
    "            test_idx = dates[(dates[self.date_idx] > days[test_start])\n",
    "                             & (dates[self.date_idx] <= days[test_end])].index\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(list(train_idx))\n",
    "            yield train_idx.to_numpy(), test_idx.to_numpy()\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048e8d1-d8a9-48e7-8672-874d0eae90c1",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "832a5bdb-33e6-4c68-946a-2af88fa2e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('data.h5') as store:\n",
    "    data = (store['model_data']\n",
    "            .dropna()\n",
    "            .drop(['open', 'close', 'low', 'high'], axis=1))\n",
    "\n",
    "data = data.drop([c for c in data.columns if 'year' in c or 'lag' in c], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744adfca-cf80-4781-9c2b-491e8b849297",
   "metadata": {},
   "source": [
    "#### Investment Universe Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ed74fbd-5b15-4ad0-ae96-dfa704cc6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.dollar_vol_rank<100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e2491-f909-4640-b95d-befc63562cc1",
   "metadata": {},
   "source": [
    "#### Creating Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2af9bd1e-b434-4c8f-a34d-85c27ecf7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.filter(like='target')\n",
    "\n",
    "X = data.drop(y.columns, axis=1)\n",
    "X = X.drop(['dollar_vol', 'dollar_vol_rank', 'volume', 'consumer_durables'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1fc010-a491-4886-a609-6484a9cca26a",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "#### Defining Cross-Validation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fdbc561-899b-4861-bde6-43ae16ea81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period_length = 63\n",
    "test_period_length = 10\n",
    "\n",
    "lookahead =1\n",
    "\n",
    "n_splits = int(3 * YEAR/test_period_length)\n",
    "\n",
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead,\n",
    "                          train_period_length=train_period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16685e47-6676-438e-b38f-c098f2471e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = f'target_{lookahead}d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af55c80c-fa62-4965-b903-8099b1aa8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.loc[:, 'label'] = (y[target] > 0).astype(int)\n",
    "y.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88ab72dd-4768-4e75-8e3c-7d3777b7324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-5, 5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9b1edce-4cc7-4c45-a834-7b4c9f6683d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['C', 'date', 'auc', 'ic', 'pval']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61e917-2d12-4d22-b4e8-5bf0a7e2465b",
   "metadata": {},
   "source": [
    "### Running Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8b3d277-5550-4b3f-bc8b-bacfcabe2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_coeffs, log_scores, log_predictions = {}, [], []\n",
    "for C in Cs:\n",
    "    print(C)\n",
    "    model = LogisticRegression(C=C,\n",
    "                               fit_intercept=True,\n",
    "                               random_state=42,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)])\n",
    "    ics = aucs = 0\n",
    "    start = time()\n",
    "    coeffs = []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X), 1):\n",
    "        X_train, y_train, = X.iloc[train_idx], y.label.iloc[train_idx]\n",
    "        pipe.fit(X=X_train, y=y_train)\n",
    "        X_test, y_test = X.iloc[test_idx], y.label.iloc[test_idx]\n",
    "        actuals = y[target].iloc[test_idx]\n",
    "        if len(y_test) < 10 or len(np.unique(y_test)) < 2:\n",
    "            continue\n",
    "        y_score = pipe.predict_proba(X_test)[:, 1]\n",
    "       \n",
    "        auc = roc_auc_score(y_score=y_score, y_true=y_test)\n",
    "        actuals = y[target].iloc[test_idx]\n",
    "        ic, pval = spearmanr(y_score, actuals)\n",
    "\n",
    "        log_predictions.append(y_test.to_frame('labels').assign(\n",
    "            predicted=y_score, C=C, actuals=actuals))\n",
    "        date = y_test.index.get_level_values('date').min()\n",
    "        log_scores.append([C, date, auc, ic * 100, pval])\n",
    "        coeffs.append(pipe.named_steps['model'].coef_)\n",
    "        ics += ic\n",
    "        aucs += auc\n",
    "        if i % 10 == 0:\n",
    "            print(f'\\t{time()-start:5.1f} | {i:03} | {ics/i:>7.2%} | {aucs/i:>7.2%}')\n",
    "\n",
    "    log_coeffs[C] = np.mean(coeffs, axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6933d-9aaa-43ad-8dd6-e0d0bbf1e8cb",
   "metadata": {},
   "source": [
    "### Results Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc0e5df9-2d67-481f-a1b3-7689f5d61719",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores = pd.DataFrame(log_scores, columns=cols)\n",
    "log_scores.to_hdf('data.h5', 'logistic/scores')\n",
    "\n",
    "log_coeffs = pd.DataFrame(log_coeffs, index=X.columns).T\n",
    "log_coeffs.to_hdf('data.h5', 'logistic/coeffs')\n",
    "\n",
    "log_predictions = pd.concat(log_predictions)\n",
    "log_predictions.to_hdf('data.h5', 'logistic/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d261f7a-a999-4709-ad29-113b7f41b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores = pd.read_hdf('data.h5', 'logistic/scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce83d962-418e-4e68-a7c6-e278a9dd61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ef6c24d-0b1f-4c75-9d08-ecebb7b47589",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores.groupby('C').auc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52f73c-916e-43c0-9811-c5539bab6846",
   "metadata": {},
   "source": [
    "### Plotting Validation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08e3046a-6c75-48d8-a296-bcbd3ea5aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ic_distribution(df, ax=None):\n",
    "    if ax is not None:\n",
    "        sns.distplot(df.ic, ax=ax)    \n",
    "    else:\n",
    "        ax = sns.distplot(df.ic)\n",
    "    mean, median = df.ic.mean(), df.ic.median()\n",
    "    ax.axvline(0, lw=1, ls='--', c='k')\n",
    "    ax.text(x=.05, y=.9, s=f'Mean: {mean:8.2f}\\nMedian: {median:5.2f}',\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center',\n",
    "            transform=ax.transAxes)\n",
    "    ax.set_xlabel('Information Coefficient')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7bc9310-1a9f-489f-b42e-c50360687e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "sns.lineplot(x='C', y='auc', data=log_scores, estimator=np.mean, label='Mean', ax=axes[0])\n",
    "by_alpha = log_scores.groupby('C').auc.agg(['mean', 'median'])\n",
    "best_auc = by_alpha['mean'].idxmax()\n",
    "by_alpha['median'].plot(logx=True, ax=axes[0], label='Median', xlim=(10e-6, 10e5))\n",
    "axes[0].axvline(best_auc, ls='--', c='k', lw=1, label='Max. Mean')\n",
    "axes[0].axvline(by_alpha['median'].idxmax(), ls='-.', c='k', lw=1, label='Max. Median')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('AUC')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_title('Area Under the Curve')\n",
    "\n",
    "plot_ic_distribution(log_scores[log_scores.C==best_auc], ax=axes[1])\n",
    "axes[1].set_title('Information Coefficient')\n",
    "\n",
    "fig.suptitle('Logistic Regression', fontsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb858a2-7da6-4cc3-a8d6-196ba9ce4cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
