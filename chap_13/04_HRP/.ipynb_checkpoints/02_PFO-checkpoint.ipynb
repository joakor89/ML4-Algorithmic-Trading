{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fa6881-d701-4d81-8735-95752c06520e",
   "metadata": {},
   "source": [
    "# PF Optimization: HRP vs Markowitz and Equal-Weighted Positions\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24eed36b-1ca9-4800-8214-b25bb0f6fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time, Warning & System\n",
    "import sys\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "# Path\n",
    "from pathlib import Path\n",
    "\n",
    "# Logbook\n",
    "from logbook import (NestedSetup, NullHandler, Logger, \n",
    "                     StreamHandler, StderrHandler, \n",
    "                     INFO, WARNING, DEBUG, ERROR)\n",
    "\n",
    "# Zipline\n",
    "from zipline import run_algorithm\n",
    "from zipline.api import (attach_pipeline, pipeline_output,\n",
    "                         date_rules, time_rules, record,get_datetime,\n",
    "                         schedule_function, commission, slippage,\n",
    "                         set_slippage, set_commission, set_max_leverage,\n",
    "                         order_target, order_target_percent,\n",
    "                         get_open_orders, cancel_order)\n",
    "from zipline.data import bundles\n",
    "from zipline.utils.run_algo import load_extensions\n",
    "from zipline.pipeline import Pipeline, CustomFactor\n",
    "from zipline.pipeline.data import Column, DataSet\n",
    "from zipline.pipeline.domain import US_EQUITIES\n",
    "from zipline.pipeline.filters import StaticAssets\n",
    "from zipline.pipeline.loaders.frame import DataFrameLoader\n",
    "\n",
    "# PypfOpt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt.hierarchical_portfolio import HRPOpt\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "# Pyfolio\n",
    "import pyfolio as pf\n",
    "from pyfolio.plotting import plot_rolling_returns, plot_rolling_sharpe\n",
    "from pyfolio.timeseries import forecast_cone_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f4fc95-39c4-4713-9c64-45a3efc5c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb21a82-08bb-439a-b678-3b834144783e",
   "metadata": {},
   "source": [
    "### Loading Zipline Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6693fe-b1a4-484e-bc8a-7c3a3aa18a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_extensions(default=True,\n",
    "                extensions=[],\n",
    "                strict=True,\n",
    "                environ=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0618722-18b5-4c8b-9f11-a560003a8f2b",
   "metadata": {},
   "source": [
    "### Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2927cf-4697-4605-93e0-48d79ab4e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string = '[{record.time: %H:%M:%S.%f}]: {record.level_name}: {record.message}'\n",
    "\n",
    "zipline_logging = NestedSetup([NullHandler(level=DEBUG),\n",
    "                               StreamHandler(sys.stdout, format_string=format_string, level=INFO),\n",
    "                               StreamHandler(sys.stdout, format_string=format_string, level=WARNING),\n",
    "                               StreamHandler(sys.stderr, level=ERROR)])\n",
    "\n",
    "zipline_logging.push_application()\n",
    "log = Logger('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39648b60-865c-421d-8c1c-45fd0b9d7a67",
   "metadata": {},
   "source": [
    "### Algo Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f5221d-9cc0-4849-bfc2-1dcf493ac597",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LONGS = 25\n",
    "\n",
    "MIN_POSITIONS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eadd76e-ad50-41cd-8f19-000031a17984",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "#### Quandl Wiki Bundel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a6f976-1625-4db1-bf21-80845d0eda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_data = bundles.load('quandl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606a457-c5d7-418c-8764-a991d0b5bfc1",
   "metadata": {},
   "source": [
    "#### ML Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabc93de-71ce-4448-a78b-2eac5d10ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(bundle):\n",
    "    path = Path('../../12_gradient_boosting_machines/data')\n",
    "    predictions = (pd.read_hdf(path / 'predictions.h5', 'lgb/train/01')\n",
    "                   .append(pd.read_hdf(path / 'predictions.h5', 'lgb/test/01').drop('y_test', axis=1)))\n",
    "    predictions = (predictions.loc[~predictions.index.duplicated()]\n",
    "                   .iloc[:, :10]\n",
    "                   .mean(1)\n",
    "                   .sort_index()\n",
    "                   .dropna()\n",
    "                  .to_frame('prediction'))\n",
    "    tickers = predictions.index.get_level_values('symbol').unique().tolist()\n",
    "\n",
    "    assets = bundle.asset_finder.lookup_symbols(tickers, as_of_date=None)\n",
    "    predicted_sids = pd.Int64Index([asset.sid for asset in assets])\n",
    "    ticker_map = dict(zip(tickers, predicted_sids))\n",
    "\n",
    "    return (predictions\n",
    "            .unstack('symbol')\n",
    "            .rename(columns=ticker_map)\n",
    "            .prediction\n",
    "            .tz_localize('UTC')), assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a0429-95cf-4968-9678-c06b49ee1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, assets = load_predictions(bundle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990e7ed-3201-4b24-aef5-089986291854",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f67cb5-d543-4015-9643-7ed384aa1e58",
   "metadata": {},
   "source": [
    "#### Defining Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0be997e-5970-4626-8043-72281d46725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalData(DataSet):\n",
    "    predictions = Column(dtype=float)\n",
    "    domain = US_EQUITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01feda5-3b2e-4a59-a892-a85b7c835966",
   "metadata": {},
   "source": [
    "#### Defining Pipeline Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd53794-eff4-432a-b98c-39ead0707508",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_loader = {SignalData.predictions:\n",
    "                     DataFrameLoader(SignalData.predictions, predictions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d582bd-4131-415d-adb6-032442daf5e7",
   "metadata": {},
   "source": [
    "### Pipeline Setup\n",
    "\n",
    "#### Custom ML Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257c9211-2227-4810-8d36-263c786cf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLSignal(CustomFactor):\n",
    "    \"\"\"Converting signals to Factor\n",
    "        so we can rank and filter in Pipeline\"\"\"\n",
    "    inputs = [SignalData.predictions]\n",
    "    window_length = 1\n",
    "\n",
    "    def compute(self, today, assets, out, predictions):\n",
    "        out[:] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc02e3-0423-4d55-9c32-00c6fc41a3ca",
   "metadata": {},
   "source": [
    "#### Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c53482e-2a20-4b91-b399-3f5bcecc8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signals():\n",
    "    signals = MLSignal()\n",
    "    return Pipeline(columns={\n",
    "        'longs' : signals.top(N_LONGS, mask=signals > 0)\n",
    "    },\n",
    "            screen=StaticAssets(assets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487b4a4-392d-456d-9829-6af20224637f",
   "metadata": {},
   "source": [
    "#### Getting Daily Pipeline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c313665-c70e-47da-98c3-bd6ec76d83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_trading_start(context, data):\n",
    "    \"\"\"\n",
    "    Called every day before market open.\n",
    "    \"\"\"\n",
    "    output = pipeline_output('signals')['longs'].astype(int)\n",
    "    context.longs = output[output!=0].index\n",
    "    if len(context.longs) < MIN_POSITIONS:\n",
    "        context.divest = set(context.portfolio.positions.keys())\n",
    "    else:\n",
    "        context.divest = context.portfolio.positions.keys() - context.longs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44709c87-7583-4395-a08e-ef69785f287e",
   "metadata": {},
   "source": [
    "### DefinING Rebalancing Logic\n",
    "\n",
    "#### Equal Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9a2062-b260-4ff7-b84b-11d5cbe0e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_equal_weighted(context, data):\n",
    "    \"\"\"\n",
    "    Execute orders according to schedule_function() date & time rules.\n",
    "    \"\"\"\n",
    "    for symbol, open_orders in get_open_orders().items():\n",
    "        for open_order in open_orders:\n",
    "            cancel_order(open_order)\n",
    "      \n",
    "    for asset in context.divest:\n",
    "        order_target(asset, target=0)\n",
    "        \n",
    "    if len(context.longs) > context.min_positions:\n",
    "        for asset in context.longs:\n",
    "            order_target_percent(asset, 1/len(context.longs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af5903-e3c3-4ce1-b070-f9b35ac3ee68",
   "metadata": {},
   "source": [
    "#### Markowitz Mean-Variance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc859397-7e4a-45a3-9c43-46f395dd1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_weights(prices, short=False):\n",
    "    \"\"\"Uses PyPortfolioOpt to optimize weights\"\"\"\n",
    "    returns = expected_returns.mean_historical_return(prices=prices, \n",
    "                                                      frequency=252)\n",
    "    cov = risk_models.sample_cov(prices=prices, frequency=252)\n",
    "\n",
    "    # get weights that maximize the Sharpe ratio\n",
    "    # using solver SCS which produces slightly fewer errors than default\n",
    "    # see https://github.com/robertmartin8/PyPortfolioOpt/issues/221\n",
    "    ef = EfficientFrontier(expected_returns=returns, \n",
    "                           cov_matrix=cov, \n",
    "                           weight_bounds=(0, 1),\n",
    "                           solver='SCS) \n",
    "    \n",
    "    weights = ef.max_sharpe()\n",
    "    if short:\n",
    "        return {asset: -weight for asset, weight in ef.clean_weights().items()}\n",
    "    else:\n",
    "        return ef.clean_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38e90d7-c582-4062-9016-f8268e67d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_markowitz(context, data):\n",
    "    \"\"\"\n",
    "    Execute orders according to schedule_function() date & time rules.\n",
    "    \"\"\"\n",
    "    for symbol, open_orders in get_open_orders().items():\n",
    "        for open_order in open_orders:\n",
    "            cancel_order(open_order)\n",
    "      \n",
    "    for asset in context.divest:\n",
    "        order_target(asset, target=0)\n",
    "        \n",
    "    if len(context.longs) > context.min_positions:\n",
    "        prices = data.history(context.longs, fields='price',\n",
    "                          bar_count=252+1, # for 1 year of returns \n",
    "                          frequency='1d')\n",
    "        try:\n",
    "            markowitz_weights = optimize_weights(prices)\n",
    "            for asset, target in markowitz_weights.items():\n",
    "                order_target_percent(asset=asset, target=target)\n",
    "        except Exception as e:\n",
    "            log.warn('{} {}'.format(get_datetime().date(), e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae57fb0-9aac-42f1-bb72-41ad3be2510a",
   "metadata": {},
   "source": [
    "#### Hierarchical Risk Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed15d971-6177-4045-9beb-c32f39cf8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_hierarchical_risk_parity(context, data):\n",
    "    \"\"\"\n",
    "    Execute orders according to schedule_function() date & time rules.\n",
    "    Uses PyPortfolioOpt to optimize weights\n",
    "    \"\"\"\n",
    "    for symbol, open_orders in get_open_orders().items():\n",
    "        for open_order in open_orders:\n",
    "            cancel_order(open_order)\n",
    "      \n",
    "    for asset in context.divest:\n",
    "        order_target(asset, target=0)\n",
    "        \n",
    "    if len(context.longs) > context.min_positions:\n",
    "        returns = (data.history(context.longs, fields='price',\n",
    "                          bar_count=252+1, # for 1 year of returns \n",
    "                          frequency='1d')\n",
    "                   .pct_change()\n",
    "                   .dropna(how='all'))\n",
    "        hrp_weights = HRPOpt(returns=returns).optimize()\n",
    "        for asset, target in hrp_weights.items():\n",
    "            order_target_percent(asset=asset, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9da374-b416-4f69-b253-a4536cddc74e",
   "metadata": {},
   "source": [
    "### Record Additional Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f9037c-c3ad-4f31-b275-e3bf134c86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_vars(context, data):\n",
    "    \"\"\"\n",
    "    Plot variables at the end of each day.\n",
    "    \"\"\"\n",
    "    record(leverage=context.account.leverage,\n",
    "           longs=context.longs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfc4a5-335a-4fdc-a36c-d8ef82beecf0",
   "metadata": {},
   "source": [
    "### Initialize Algorithm with PF Optimization Algorithm\n",
    "\n",
    "#### Selecting Portfolio Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34d7a3e6-abec-4cbd-afe2-92f7d8ef6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_algos = {\n",
    "    'ew': rebalance_equal_weighted,\n",
    "    'markowitz': rebalance_markowitz,        \n",
    "    'hrp': rebalance_hierarchical_risk_parity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3dd13ea-ced7-42a8-844b-e3a38d582ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_labels = {\n",
    "    'ew': 'Equal Weighted', \n",
    "    'markowitz': 'Markowitz (MFT)',\n",
    "    'hrp': 'Hierarchical Risk Parity'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "458f9f5c-09c3-427d-a231-af50efa1f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pf_algo = 'hrp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6649454-e3da-4238-8e87-e3f46093caae",
   "metadata": {},
   "source": [
    "### Schedule Rebalancing using Selected Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fc8a14d-0451-469d-b1fc-3675bcecf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(context):\n",
    "    \"\"\"\n",
    "    Called once at the start of the algorithm.\n",
    "    \"\"\"\n",
    "    context.n_longs = N_LONGS\n",
    "    context.min_positions = MIN_POSITIONS\n",
    "    context.universe = assets\n",
    "    context.trades = pd.Series()\n",
    "    context.longs = 0\n",
    "    context.pf_algo = pf_algos.get(selected_pf_algo)\n",
    "    \n",
    "    set_slippage(slippage.FixedSlippage(spread=0.00))\n",
    "    set_commission(commission.PerShare(cost=0.001, min_trade_cost=1))\n",
    "\n",
    "    schedule_function(context.pf_algo,\n",
    "                      # run every day after market open\n",
    "                      date_rules.every_day(),\n",
    "                      time_rules.market_open(hours=1, minutes=30))    \n",
    "\n",
    "    schedule_function(record_vars,\n",
    "                      date_rules.every_day(),\n",
    "                      time_rules.market_close())\n",
    "\n",
    "    pipeline = compute_signals()\n",
    "    attach_pipeline(pipeline, 'signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408cd944-52a0-4999-88be-d4421f9595da",
   "metadata": {},
   "source": [
    "### Running Trading Algorithm for each PF Optimization Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f953f25-7b4e-4f10-98e2-c3d23530d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = predictions.index.get_level_values('date')\n",
    "\n",
    "start_date, end_date = dates.min(), dates.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "342dc5df-3f52-4fce-ba57-c7809c7662de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start: {}\\nEnd:   {}'.format(start_date.date(), end_date.date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f1f5100-4ad6-40d4-998f-3d435717986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "results = run_algorithm(start=start_date,\n",
    "                        end=end_date,\n",
    "                        initialize=initialize,\n",
    "                        before_trading_start=before_trading_start,\n",
    "                        capital_base=1e5,\n",
    "                        data_frequency='daily',\n",
    "                        bundle='quandl',\n",
    "                        custom_loader=signal_loader)  \n",
    "\n",
    "print('Duration: {:.2f}s'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d98be-4ea1-4fc0-be0e-6d0d22da6cb3",
   "metadata": {},
   "source": [
    "#### Persisting Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d21bbfa8-8759-481c-b1e6-e8554afb704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d57096e7-2fb8-4e69-bc7d-fabc30fb38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('backtests.h5') as store:\n",
    "    store.put('returns/{}'.format(selected_pf_algo), returns)\n",
    "    store.put('positions/{}'.format(selected_pf_algo), positions)\n",
    "    store.put('transactions/{}'.format(selected_pf_algo), transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f2c2d9c-8d77-48d3-b9cf-7e4a09735f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('backtests.h5') as store:\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b39590-9209-4b8c-a455-ddf5f5fc7453",
   "metadata": {},
   "source": [
    "### Comparing Results using Pyfolio\n",
    "\n",
    "#### Loading Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0a8001e-54fd-4821-8c0e-f8c1f1a0cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = web.DataReader('SP500', 'fred', '2014', '2018').squeeze()\n",
    "\n",
    "benchmark = benchmark.pct_change().tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead416e-8f5f-43fb-b741-916e26c22819",
   "metadata": {},
   "source": [
    "### Cumulative Returns & Rolling Sharpe Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4866d814-5103-42b2-aa61-4a85b088917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(18, 8))\n",
    "\n",
    "for i, (algo, label) in enumerate(algo_labels.items()):\n",
    "    returns = pd.read_hdf('backtests.h5', f'returns/{algo}')    \n",
    "    plot_rolling_returns(returns,\n",
    "                         factor_returns=benchmark,\n",
    "                         live_start_date='2017-01-01',\n",
    "                         logy=False,\n",
    "                         cone_std=2,\n",
    "                         legend_loc='best',\n",
    "                         volatility_match=False,\n",
    "                         cone_function=forecast_cone_bootstrap,\n",
    "                        ax=axes[0][i])\n",
    "    plot_rolling_sharpe(returns, ax=axes[1][i], rolling_window=63)\n",
    "    axes[0][i].set_title(f'{label} | Cumulative Returns')\n",
    "    axes[1][i].set_title(f'{label} | Rolling Sharpe Ratio')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3227a5-7a74-47c4-b904-4b2f5db315e9",
   "metadata": {},
   "source": [
    "### Tear Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16e86190-0355-438d-8165-19890bd02d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(experiment='hrp'):\n",
    "    with pd.HDFStore('backtests.h5') as store:\n",
    "        returns = store.get('returns/{}'.format(experiment))\n",
    "        positions = store.get('positions/{}'.format(experiment))\n",
    "        transactions = store.get('transactions/{}'.format(experiment))\n",
    "    return returns, positions, transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4003bcf-2c73-4e31-ba6a-dbfcf2b3881b",
   "metadata": {},
   "source": [
    "#### Equally Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f906caa9-f2d6-4bd5-84bf-28c62e23074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'ew'\n",
    "returns, positions, transactions = load_results(experiment)\n",
    "\n",
    "pf.create_full_tear_sheet(returns, \n",
    "                          positions=positions, \n",
    "                          transactions=transactions,\n",
    "                          benchmark_rets=benchmark,\n",
    "                          live_start_date='2017-01-01', \n",
    "                          round_trips=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b4a9e-ae25-4ac3-bae3-cecafb3c5f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
