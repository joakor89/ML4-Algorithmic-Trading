{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581c9f9a-7c9f-47b5-828a-5aa454632a03",
   "metadata": {},
   "source": [
    "# How to Train Your Own Word Vector Embeddings Using Gensim\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5cdce08-b204-444b-8a8b-7a299cfc1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Path, Time & Collection\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# SciPy\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "\n",
    "# Gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdd6913-7ba6-46f1-acd5-c6eb0d0e6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509990d6-4bfe-4852-8cf0-a6f447d0c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_path = Path('data', 'fin_news')\n",
    "\n",
    "data_path = news_path / 'data'\n",
    "\n",
    "analogy_path = Path('data', 'analogies-en.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71e6483-da30-4390-bad8-4e2afe33af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f'{h:02.0f}:{m:02.0f}:{s:02.0f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ac138-3304-435b-b9dc-0b63e4ba9f48",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf0ed08-cf28-4a1a-9664-f7c0962567b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_path = news_path / 'gensim'\n",
    "\n",
    "if not gensim_path.exists():\n",
    "    gensim_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0583e6-422c-4cd7-af60-37b9f6801fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS = 3           \n",
    "MIN_FREQ = 100\n",
    "WINDOW_SIZE = 5\n",
    "EMBEDDING_SIZE = 300\n",
    "NEGATIVE_SAMPLES = 20\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8762a5-e200-4429-b4b1-5e9096b7949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = f'articles_{NGRAMS}_grams.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f933c2-c284-4d46-a1d2-7f143ecdfaab",
   "metadata": {},
   "source": [
    "### Sentence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be05ad9-91a9-4bb9-9c53-080e9df01f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_path = data_path / FILE_NAME\n",
    "\n",
    "sentences = LineSentence(str(sentence_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730f920-941d-4b5a-a9cd-c8729c4d1a6e",
   "metadata": {},
   "source": [
    "#### Training `word2vec` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f149ffe-8cc8-49d1-9e99-29950a824a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "model = Word2Vec(sentences, \n",
    "                 sg=1, \n",
    "                 size=EMBEDDING_SIZE, \n",
    "                 window=WINDOW_SIZE,\n",
    "                 min_count=MIN_FREQ, \n",
    "                 negative=NEGATIVE_SAMPLES, \n",
    "                 workers=8,\n",
    "                 iter=EPOCHS, \n",
    "                 alpha=0.05)\n",
    "\n",
    "\n",
    "model.save(str(gensim_path / 'word2vec.model'))\n",
    "\n",
    "\n",
    "model.wv.save(str(gensim_path / 'word_vectors.bin'))\n",
    "print('Duration:', format_time(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff13d3-6d9b-43f2-820b-2c4b662ed79e",
   "metadata": {},
   "source": [
    "### Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a401e1dd-78c0-40b8-a3e1-e1d307b4cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {'capital-common-countries':'Capitals',\n",
    "            'capital-world':'Capitals RoW',\n",
    "            'city-in-state':'City-State',\n",
    "            'currency':'Currency',\n",
    "            'family':'Famliy',\n",
    "            'gram1-adjective-to-adverb':'Adj-Adverb',\n",
    "            'gram2-opposite':'Opposite',\n",
    "            'gram3-comparative':'Comparative',\n",
    "            'gram4-superlative':'Superlative',\n",
    "            'gram5-present-participle':'Pres. Part.',\n",
    "            'gram6-nationality-adjective':'Nationality',\n",
    "            'gram7-past-tense':'Past Tense',\n",
    "            'gram8-plural':'Plural',\n",
    "            'gram9-plural-verbs':'Plural Verbs',\n",
    "            'total':'Total'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f72e106-2eb3-4275-a9d0-2130f83542d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_by_category(acc, detail=True):\n",
    "    results = [[c['section'], len(c['correct']), len(c['incorrect'])] for c in acc]\n",
    "    results = pd.DataFrame(results, columns=['category', 'correct', 'incorrect'])\n",
    "    results['average'] = results.correct.div(results[['correct', 'incorrect']].sum(1))\n",
    "    if detail:\n",
    "        print(results.sort_values('average', ascending=False))\n",
    "    return results.loc[results.category=='total', ['correct', 'incorrect', 'average']].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed10387-a5d6-4a90-9e61-e5ff49799c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_accuracy = model.wv.accuracy(analogy_path.as_posix(), case_insensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b136842d-d991-415c-9d19-827f237ef58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = accuracy_by_category(detailed_accuracy)\n",
    "\n",
    "print('Base Accuracy: Correct {:,.0f} | Wrong {:,.0f} | Avg {:,.2%}\\n'.format(*summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708d7894-d4b4-4286-a1a9-e31f02b61948",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim = model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=20)\n",
    "\n",
    "pd.DataFrame(most_sim, columns=['token', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e319ee5-afd2-4116-bff4-905584fb0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(sentence_path.read_text().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8b2034b-16aa-418a-ae69-27b9d7e4a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = pd.DataFrame(counter.most_common(), columns=['token', 'count'])\n",
    "\n",
    "most_common = most_common[most_common['count']> MIN_FREQ]\n",
    "\n",
    "most_common['p'] = np.log(most_common['count'])/np.log(most_common['count']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ac320f-e42c-45b1-b4c3-95e782079433",
   "metadata": {},
   "outputs": [],
   "source": [
    "similars = pd.DataFrame()\n",
    "\n",
    "for token in np.random.choice(most_common.token, size=10, p=most_common.p):\n",
    "    similars[token] = [s[0] for s in model.wv.most_similar(token)]\n",
    "similars.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a26a9c-840f-4bfd-b503-84f29ee5efe3",
   "metadata": {},
   "source": [
    "### Keeping Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e1ed5e0-5bd2-4402-8548-a04bcc6d7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [summary]\n",
    "\n",
    "best_accuracy = summary[-1]\n",
    "\n",
    "for i in range(1, 10):\n",
    "    start = time()\n",
    "    model.train(sentences, epochs=1, total_examples=model.corpus_count)\n",
    "    detailed_accuracy = model.wv.accuracy(analogy_path)\n",
    "    accuracies.append(accuracy_by_category(detailed_accuracy, detail=False))\n",
    "    print(f'{i:02} | Duration: {format_time(time() - start)} | Accuracy: {accuracies[-1][-1]:.2%} ')\n",
    "    if accuracies[-1][-1] > best_accuracy:\n",
    "        model.save(str(gensim_path / f'word2vec_{i:02}.model'))\n",
    "        model.wv.save(str(gensim_path / f'word_vectors_{i:02}.bin'))\n",
    "        best_accuracy = accuracies[-1][-1]\n",
    "    (pd.DataFrame(accuracies, \n",
    "                 columns=['correct', 'wrong', 'average'])\n",
    "     .to_csv(gensim_path / 'accuracies.csv', index=False))\n",
    "model.wv.save(str(gensim_path / 'word_vectors_final.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53aefd-b684-4887-839c-ba34589a45f4",
   "metadata": {},
   "source": [
    "### Evaluating Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8e456ff-d147-4987-ac16-c028fdfaee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(accuracies, columns=['correct', 'wrong', 'average'], index=list(range(1, len(accuracies) + 1))).average.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d5f2f2e-2f81-42dc-9432-28f0de2c1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Word2Vec.load((gensim_path / 'word2vec_06.model').as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "350d1d77-b58f-474e-b5d7-2d2037b4a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_accuracy = best_model.wv.accuracy(analogy_path.as_posix(), case_insensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dd2fa94-e18a-41b5-960c-1c12f289d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = accuracy_by_category(detailed_accuracy)\n",
    "\n",
    "print('Base Accuracy: Correct {:,.0f} | Wrong {:,.0f} | Avg {:,.2%}\\n'.format(*summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab4f451f-8a7c-495b-9066-b42e725c15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[c['section'], len(c['correct']), len(c['incorrect'])] for c in detailed_accuracy]\n",
    "results = pd.DataFrame(results, columns=['category', 'correct', 'incorrect'])\n",
    "results['category'] = results.category.map(cat_dict)\n",
    "results['average'] = results.correct.div(results[['correct', 'incorrect']].sum(1))\n",
    "results = results.rename(columns=str.capitalize).set_index('Category')\n",
    "total = results.loc['Total']\n",
    "results = results.drop('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bb7a09d-a9fd-48c6-9b0b-8b8745cf875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim = best_model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=20)\n",
    "\n",
    "pd.DataFrame(most_sim, columns=['token', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0722ae49-2240-4da0-a496-e8649babb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16, 5), ncols=2)\n",
    "\n",
    "axes[0] = results.loc[:, ['Correct', 'Incorrect']].plot.bar(stacked=True, ax=axes[0]\n",
    "                                                           , title='Analogy Accuracy')\n",
    "ax1 = results.loc[:, ['Average']].plot(ax=axes[0], secondary_y=True, lw=1, c='k', rot=35)\n",
    "ax1.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "(pd.DataFrame(most_sim, columns=['token', 'similarity'])\n",
    " .set_index('token').similarity\n",
    " .sort_values().tail(10).plot.barh(xlim=(.3, .37), ax=axes[1], title='Closest matches for Woman + King - Man'))\n",
    "fig.tight_layout();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e055e207-1012-45b1-bbe2-a39366cad987",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(sentence_path.read_text().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e712cf3-53e0-40f1-9927-aec3bbbf5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = pd.DataFrame(counter.most_common(), columns=['token', 'count'])\n",
    "\n",
    "most_common = most_common[most_common['count']> MIN_FREQ]\n",
    "\n",
    "most_common['p'] = np.log(most_common['count'])/np.log(most_common['count']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d52dff03-88f9-4507-bd3d-b9ab0402796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similars = pd.DataFrame()\n",
    "\n",
    "for token in np.random.choice(most_common.token, size=10, p=most_common.p):\n",
    "    similars[token] = [s[0] for s in best_model.wv.most_similar(token)]\n",
    "similars.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f9b84f-3752-4c76-b143-3003ab5846bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "similars.T.iloc[:5, :5].to_csv('figures/most_similar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdba5a6-6df1-4ec5-aeaf-e434f9383b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
